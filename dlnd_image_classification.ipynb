{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 1:\n",
      "Image - Min Value: 5 Max Value: 254\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 9 Name: truck\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9c81ebb470>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 1\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    a = .1\n",
    "    b = .9\n",
    "    image_min = 0\n",
    "    image_max = 255\n",
    "    return a + (((x - image_min) * (b-a) )/(image_max - image_min))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "labels_value = range(10)\n",
    "lb.fit(labels_value)\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    return lb.transform(x)\n",
    "    \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x = tf.placeholder(tf.float32, shape = [None,image_shape[0],image_shape[1],image_shape[2]], name = \"x\")\n",
    "    return x\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    label_tf = tf.placeholder(tf.float32, shape=[None,n_classes], name=\"y\")\n",
    "    return label_tf\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    keep_prob = tf.placeholder(tf.float32, None, name=\"keep_prob\")\n",
    "    return keep_prob\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 32, 32, 5]\n",
      "[2, 2, 5, 10]\n",
      "Tensor(\"Relu_6:0\", shape=(?, 4, 4, 10), dtype=float32)\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    dimension = x_tensor.get_shape().as_list() #create list that holds the dimensions of the input\n",
    "    print(dimension)\n",
    "    shape = list(conv_ksize +(dimension[-1],) + (conv_num_outputs,)) #reshape for convolution layer.\n",
    "    print(shape)\n",
    "    weights = tf.Variable(tf.truncated_normal(shape,0,0.05)) #set weights to a truncated normal distribution\n",
    "    bias = tf.Variable(tf.zeros(conv_num_outputs)) #set biases to zero\n",
    "    padding = 'SAME' #set padding to 'SAME'\n",
    "    #print(weights)\n",
    "    #print(bias)\n",
    "    conv_layer = tf.nn.conv2d(x_tensor, weights, list((1,)+conv_strides+(1,)),padding) #use build in tensorflow conv2d \n",
    "    #print(conv_layer)\n",
    "    conv_layer = tf.nn.bias_add(conv_layer, bias) #use built in tf.nn.bias_add to add the bias layer\n",
    "    #print(conv_layer)\n",
    "    conv_layer = tf.nn.max_pool(conv_layer,ksize=[1] + list(pool_ksize) + [1], strides =[1] + list(pool_strides) + [1], padding='SAME')\n",
    "    # using the built in tf.nn.max_pool function\n",
    "    conv_layer = tf.nn.relu(conv_layer) #use relu activation\n",
    "    #print(conv_layer)\n",
    "\n",
    "    print(conv_layer)\n",
    "    return conv_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    flat = tf.contrib.layers.flatten(x_tensor, None, None)\n",
    "    return flat\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    ful_con = tf.contrib.layers.fully_connected(\n",
    "    x_tensor,\n",
    "    num_outputs,)\n",
    "    return ful_con\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    ful_con = tf.contrib.layers.fully_connected(\n",
    "    x_tensor,\n",
    "    num_outputs,\n",
    "    activation_fn=None,\n",
    "    normalizer_fn=None,\n",
    "    normalizer_params=None,\n",
    "    )\n",
    "    return ful_con\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 32, 32, 3]\n",
      "[8, 8, 3, 64]\n",
      "Tensor(\"Relu:0\", shape=(?, 4, 4, 64), dtype=float32)\n",
      "[None, 4, 4, 64]\n",
      "[8, 8, 64, 64]\n",
      "Tensor(\"Relu_1:0\", shape=(?, 1, 1, 64), dtype=float32)\n",
      "[None, 1, 1, 64]\n",
      "[8, 8, 64, 64]\n",
      "Tensor(\"Relu_2:0\", shape=(?, 1, 1, 64), dtype=float32)\n",
      "[None, 32, 32, 3]\n",
      "[8, 8, 3, 64]\n",
      "Tensor(\"Relu_3:0\", shape=(?, 4, 4, 64), dtype=float32)\n",
      "[None, 4, 4, 64]\n",
      "[8, 8, 64, 64]\n",
      "Tensor(\"Relu_4:0\", shape=(?, 1, 1, 64), dtype=float32)\n",
      "[None, 1, 1, 64]\n",
      "[8, 8, 64, 64]\n",
      "Tensor(\"Relu_5:0\", shape=(?, 1, 1, 64), dtype=float32)\n",
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    conv_ksize=(8,8)\n",
    "    conv_num_outputs=conv_ksize[0]*conv_ksize[1] \n",
    "    conv_strides=(conv_ksize[0]/2,conv_ksize[1]/2) \n",
    "    pool_ksize=(conv_strides[0], conv_strides[1])\n",
    "    pool_strides=(pool_ksize[0]/2, pool_ksize[1]/2)\n",
    "    num_outputs = 10\n",
    "\n",
    "    comax1 = conv2d_maxpool(x, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    comax2 = conv2d_maxpool(comax1, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    comax3 = conv2d_maxpool(comax2, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    flatten_layer = flatten(comax3)\n",
    "    flatten_layer = tf.nn.dropout(flatten_layer,keep_prob)\n",
    "    \n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    # Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "\n",
    "    fully_conn_layer = fully_conn(flatten_layer, num_outputs*2)\n",
    "    #fully_conn_layer = tf.nn.dropout(fully_conn_layer, keep_prob)\n",
    "    #fully_conn_layer = fully_conn(fully_conn_layer, num_outputs*2)\n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    output_layer = output(fully_conn_layer, num_outputs)\n",
    "    return output_layer\n",
    "    \n",
    "    \n",
    "    # TODO: return output\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "\n",
    "    session.run(optimizer, feed_dict={x: feature_batch, y: label_batch, keep_prob: keep_probability})\n",
    "    pass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict = {x:feature_batch, y:label_batch, keep_prob:1.})\n",
    "    acc = session.run(accuracy, feed_dict = {x:feature_batch, y:label_batch, keep_prob:1.})\n",
    "    val_cost, val_acc = session.run([cost, accuracy], feed_dict={x:valid_features, y:valid_labels, keep_prob:1.})\n",
    "    print(\"Loss: \" + str(loss) + \" Accuracy: \" + str(acc) + \" Validation Loss: \" + str(val_cost) + \" Validation Accuracy: \" + str(val_acc))\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 200\n",
    "batch_size = 2056\n",
    "keep_probability = .85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 2.28995 Accuracy: 0.0979381 Validation Loss: 2.28899 Validation Accuracy: 0.107\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 2.26182 Accuracy: 0.141753 Validation Loss: 2.26076 Validation Accuracy: 0.1296\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 2.22301 Accuracy: 0.143041 Validation Loss: 2.22278 Validation Accuracy: 0.132\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 2.17932 Accuracy: 0.167526 Validation Loss: 2.17517 Validation Accuracy: 0.155\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 2.13688 Accuracy: 0.180412 Validation Loss: 2.12487 Validation Accuracy: 0.184\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 2.09257 Accuracy: 0.213918 Validation Loss: 2.07663 Validation Accuracy: 0.2116\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 2.05766 Accuracy: 0.225515 Validation Loss: 2.03824 Validation Accuracy: 0.2292\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 2.01691 Accuracy: 0.234536 Validation Loss: 1.99447 Validation Accuracy: 0.2412\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 1.97304 Accuracy: 0.271907 Validation Loss: 1.95264 Validation Accuracy: 0.2638\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 1.93214 Accuracy: 0.287371 Validation Loss: 1.91053 Validation Accuracy: 0.28\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 1.90489 Accuracy: 0.29768 Validation Loss: 1.8882 Validation Accuracy: 0.2926\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 1.88287 Accuracy: 0.306701 Validation Loss: 1.86236 Validation Accuracy: 0.2966\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 1.85308 Accuracy: 0.322165 Validation Loss: 1.84609 Validation Accuracy: 0.296\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 1.82662 Accuracy: 0.329897 Validation Loss: 1.8182 Validation Accuracy: 0.309\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 1.8017 Accuracy: 0.349227 Validation Loss: 1.8013 Validation Accuracy: 0.3116\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 1.77289 Accuracy: 0.363402 Validation Loss: 1.77642 Validation Accuracy: 0.3228\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 1.74778 Accuracy: 0.369845 Validation Loss: 1.75607 Validation Accuracy: 0.3336\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 1.73533 Accuracy: 0.377577 Validation Loss: 1.748 Validation Accuracy: 0.3378\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 1.7127 Accuracy: 0.391753 Validation Loss: 1.72988 Validation Accuracy: 0.3516\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 1.69806 Accuracy: 0.385309 Validation Loss: 1.72077 Validation Accuracy: 0.3576\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 1.68197 Accuracy: 0.407216 Validation Loss: 1.71056 Validation Accuracy: 0.3632\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss: 1.66406 Accuracy: 0.409794 Validation Loss: 1.69258 Validation Accuracy: 0.361\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss: 1.64261 Accuracy: 0.425258 Validation Loss: 1.67981 Validation Accuracy: 0.371\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss: 1.61977 Accuracy: 0.438144 Validation Loss: 1.66163 Validation Accuracy: 0.3828\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss: 1.60927 Accuracy: 0.447165 Validation Loss: 1.65232 Validation Accuracy: 0.3862\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss: 1.5867 Accuracy: 0.448454 Validation Loss: 1.63674 Validation Accuracy: 0.3858\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss: 1.57408 Accuracy: 0.447165 Validation Loss: 1.62717 Validation Accuracy: 0.4016\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss: 1.57242 Accuracy: 0.456185 Validation Loss: 1.63041 Validation Accuracy: 0.3922\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss: 1.54093 Accuracy: 0.463917 Validation Loss: 1.60283 Validation Accuracy: 0.407\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss: 1.52449 Accuracy: 0.458763 Validation Loss: 1.59396 Validation Accuracy: 0.4082\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss: 1.51348 Accuracy: 0.458763 Validation Loss: 1.58888 Validation Accuracy: 0.4102\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss: 1.49524 Accuracy: 0.465206 Validation Loss: 1.57421 Validation Accuracy: 0.4162\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss: 1.48557 Accuracy: 0.463917 Validation Loss: 1.56887 Validation Accuracy: 0.4196\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss: 1.47476 Accuracy: 0.484536 Validation Loss: 1.5593 Validation Accuracy: 0.4228\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss: 1.45816 Accuracy: 0.478093 Validation Loss: 1.55053 Validation Accuracy: 0.4276\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss: 1.44875 Accuracy: 0.501289 Validation Loss: 1.54287 Validation Accuracy: 0.4316\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss: 1.44126 Accuracy: 0.497423 Validation Loss: 1.54017 Validation Accuracy: 0.4342\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss: 1.4263 Accuracy: 0.501289 Validation Loss: 1.52913 Validation Accuracy: 0.4366\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss: 1.41527 Accuracy: 0.514175 Validation Loss: 1.52517 Validation Accuracy: 0.4364\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss: 1.40519 Accuracy: 0.502577 Validation Loss: 1.51549 Validation Accuracy: 0.441\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss: 1.40168 Accuracy: 0.514175 Validation Loss: 1.52382 Validation Accuracy: 0.4422\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss: 1.39272 Accuracy: 0.51933 Validation Loss: 1.51242 Validation Accuracy: 0.4398\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss: 1.40102 Accuracy: 0.509021 Validation Loss: 1.53234 Validation Accuracy: 0.4434\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss: 1.39832 Accuracy: 0.506443 Validation Loss: 1.52737 Validation Accuracy: 0.4428\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss: 1.37817 Accuracy: 0.501289 Validation Loss: 1.51486 Validation Accuracy: 0.4522\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss: 1.35865 Accuracy: 0.525773 Validation Loss: 1.48574 Validation Accuracy: 0.4514\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss: 1.35621 Accuracy: 0.524485 Validation Loss: 1.49567 Validation Accuracy: 0.456\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss: 1.33977 Accuracy: 0.539948 Validation Loss: 1.48029 Validation Accuracy: 0.4564\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss: 1.33378 Accuracy: 0.52835 Validation Loss: 1.48143 Validation Accuracy: 0.4606\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss: 1.32417 Accuracy: 0.534794 Validation Loss: 1.47283 Validation Accuracy: 0.463\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss: 1.31485 Accuracy: 0.534794 Validation Loss: 1.46942 Validation Accuracy: 0.4646\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss: 1.31366 Accuracy: 0.539948 Validation Loss: 1.47294 Validation Accuracy: 0.461\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss: 1.31366 Accuracy: 0.533505 Validation Loss: 1.47686 Validation Accuracy: 0.4594\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss: 1.28968 Accuracy: 0.554124 Validation Loss: 1.45043 Validation Accuracy: 0.4682\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss: 1.29167 Accuracy: 0.534794 Validation Loss: 1.46475 Validation Accuracy: 0.468\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss: 1.27402 Accuracy: 0.559278 Validation Loss: 1.44651 Validation Accuracy: 0.4688\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss: 1.26629 Accuracy: 0.560567 Validation Loss: 1.44879 Validation Accuracy: 0.4712\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss: 1.25646 Accuracy: 0.570876 Validation Loss: 1.43738 Validation Accuracy: 0.4742\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss: 1.2453 Accuracy: 0.576031 Validation Loss: 1.434 Validation Accuracy: 0.4776\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss: 1.25228 Accuracy: 0.573454 Validation Loss: 1.44763 Validation Accuracy: 0.4726\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss: 1.23482 Accuracy: 0.579897 Validation Loss: 1.42916 Validation Accuracy: 0.4794\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss: 1.22839 Accuracy: 0.583763 Validation Loss: 1.42059 Validation Accuracy: 0.483\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss: 1.21559 Accuracy: 0.588917 Validation Loss: 1.41779 Validation Accuracy: 0.483\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss: 1.21243 Accuracy: 0.585051 Validation Loss: 1.42395 Validation Accuracy: 0.4832\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss: 1.20224 Accuracy: 0.592783 Validation Loss: 1.41469 Validation Accuracy: 0.4832\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss: 1.20107 Accuracy: 0.597938 Validation Loss: 1.4201 Validation Accuracy: 0.481\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss: 1.18903 Accuracy: 0.591495 Validation Loss: 1.41219 Validation Accuracy: 0.4848\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss: 1.18563 Accuracy: 0.601804 Validation Loss: 1.40508 Validation Accuracy: 0.4914\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss: 1.18854 Accuracy: 0.591495 Validation Loss: 1.41971 Validation Accuracy: 0.482\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss: 1.18137 Accuracy: 0.581186 Validation Loss: 1.41166 Validation Accuracy: 0.4866\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss: 1.1923 Accuracy: 0.583763 Validation Loss: 1.43368 Validation Accuracy: 0.4812\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss: 1.15715 Accuracy: 0.608247 Validation Loss: 1.39353 Validation Accuracy: 0.4926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73, CIFAR-10 Batch 1:  Loss: 1.15015 Accuracy: 0.600515 Validation Loss: 1.38654 Validation Accuracy: 0.4946\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss: 1.17512 Accuracy: 0.588917 Validation Loss: 1.43365 Validation Accuracy: 0.4846\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss: 1.13412 Accuracy: 0.613402 Validation Loss: 1.38009 Validation Accuracy: 0.4956\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss: 1.13564 Accuracy: 0.612113 Validation Loss: 1.39743 Validation Accuracy: 0.4886\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss: 1.1257 Accuracy: 0.609536 Validation Loss: 1.39322 Validation Accuracy: 0.4874\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss: 1.11538 Accuracy: 0.612113 Validation Loss: 1.3833 Validation Accuracy: 0.4952\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss: 1.12746 Accuracy: 0.614691 Validation Loss: 1.40167 Validation Accuracy: 0.4864\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss: 1.11108 Accuracy: 0.615979 Validation Loss: 1.37967 Validation Accuracy: 0.4988\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss: 1.12859 Accuracy: 0.599227 Validation Loss: 1.40945 Validation Accuracy: 0.4908\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss: 1.11044 Accuracy: 0.617268 Validation Loss: 1.39004 Validation Accuracy: 0.4946\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss: 1.09612 Accuracy: 0.635309 Validation Loss: 1.38839 Validation Accuracy: 0.498\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss: 1.07459 Accuracy: 0.619845 Validation Loss: 1.3599 Validation Accuracy: 0.5028\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss: 1.07484 Accuracy: 0.637887 Validation Loss: 1.37635 Validation Accuracy: 0.4976\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss: 1.08104 Accuracy: 0.632732 Validation Loss: 1.3838 Validation Accuracy: 0.4966\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss: 1.07052 Accuracy: 0.636598 Validation Loss: 1.37256 Validation Accuracy: 0.499\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss: 1.05353 Accuracy: 0.622423 Validation Loss: 1.35853 Validation Accuracy: 0.5054\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss: 1.0497 Accuracy: 0.637887 Validation Loss: 1.36828 Validation Accuracy: 0.5002\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss: 1.05958 Accuracy: 0.628866 Validation Loss: 1.38997 Validation Accuracy: 0.4914\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss: 1.05474 Accuracy: 0.636598 Validation Loss: 1.37084 Validation Accuracy: 0.5058\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss: 1.04211 Accuracy: 0.64433 Validation Loss: 1.37658 Validation Accuracy: 0.4988\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss: 1.03357 Accuracy: 0.635309 Validation Loss: 1.36397 Validation Accuracy: 0.5066\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss: 1.0152 Accuracy: 0.650773 Validation Loss: 1.34959 Validation Accuracy: 0.509\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss: 1.03131 Accuracy: 0.646907 Validation Loss: 1.375 Validation Accuracy: 0.499\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss: 1.01122 Accuracy: 0.650773 Validation Loss: 1.35296 Validation Accuracy: 0.5098\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss: 0.997576 Accuracy: 0.65335 Validation Loss: 1.35292 Validation Accuracy: 0.5052\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss: 0.98981 Accuracy: 0.655928 Validation Loss: 1.34096 Validation Accuracy: 0.5124\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss: 0.995606 Accuracy: 0.662371 Validation Loss: 1.36257 Validation Accuracy: 0.5056\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss: 0.996682 Accuracy: 0.654639 Validation Loss: 1.35844 Validation Accuracy: 0.5066\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 2.29882 Accuracy: 0.104381 Validation Loss: 2.29765 Validation Accuracy: 0.1122\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss: 2.29114 Accuracy: 0.136598 Validation Loss: 2.29175 Validation Accuracy: 0.127\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss: 2.26949 Accuracy: 0.18299 Validation Loss: 2.27587 Validation Accuracy: 0.1706\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss: 2.2576 Accuracy: 0.145619 Validation Loss: 2.25703 Validation Accuracy: 0.159\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss: 2.22841 Accuracy: 0.194588 Validation Loss: 2.23036 Validation Accuracy: 0.1798\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 2.20099 Accuracy: 0.225515 Validation Loss: 2.19012 Validation Accuracy: 0.2266\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss: 2.1354 Accuracy: 0.208763 Validation Loss: 2.14006 Validation Accuracy: 0.1858\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss: 2.06666 Accuracy: 0.219072 Validation Loss: 2.08684 Validation Accuracy: 0.2198\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss: 2.02227 Accuracy: 0.235825 Validation Loss: 2.02497 Validation Accuracy: 0.2512\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss: 1.98188 Accuracy: 0.213918 Validation Loss: 1.98325 Validation Accuracy: 0.2422\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 2.02384 Accuracy: 0.224227 Validation Loss: 1.99491 Validation Accuracy: 0.2332\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss: 1.92793 Accuracy: 0.265464 Validation Loss: 1.90404 Validation Accuracy: 0.279\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss: 1.87719 Accuracy: 0.283505 Validation Loss: 1.88336 Validation Accuracy: 0.2888\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss: 1.86145 Accuracy: 0.30799 Validation Loss: 1.86487 Validation Accuracy: 0.2982\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss: 1.88266 Accuracy: 0.268041 Validation Loss: 1.85308 Validation Accuracy: 0.2986\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 1.86659 Accuracy: 0.302835 Validation Loss: 1.83139 Validation Accuracy: 0.306\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss: 1.84588 Accuracy: 0.286082 Validation Loss: 1.81119 Validation Accuracy: 0.3184\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss: 1.7929 Accuracy: 0.319588 Validation Loss: 1.80332 Validation Accuracy: 0.3172\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss: 1.78321 Accuracy: 0.319588 Validation Loss: 1.78782 Validation Accuracy: 0.326\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss: 1.82733 Accuracy: 0.284794 Validation Loss: 1.78699 Validation Accuracy: 0.3216\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 1.79427 Accuracy: 0.33634 Validation Loss: 1.77096 Validation Accuracy: 0.3326\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss: 1.7846 Accuracy: 0.311856 Validation Loss: 1.75306 Validation Accuracy: 0.3424\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss: 1.73916 Accuracy: 0.351804 Validation Loss: 1.75736 Validation Accuracy: 0.3374\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss: 1.73826 Accuracy: 0.335052 Validation Loss: 1.74598 Validation Accuracy: 0.3408\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss: 1.78139 Accuracy: 0.337629 Validation Loss: 1.7295 Validation Accuracy: 0.3502\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 1.74014 Accuracy: 0.367268 Validation Loss: 1.72231 Validation Accuracy: 0.3544\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss: 1.75564 Accuracy: 0.340206 Validation Loss: 1.73249 Validation Accuracy: 0.364\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss: 1.72127 Accuracy: 0.369845 Validation Loss: 1.74314 Validation Accuracy: 0.3494\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss: 1.69413 Accuracy: 0.367268 Validation Loss: 1.708 Validation Accuracy: 0.3616\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss: 1.73388 Accuracy: 0.349227 Validation Loss: 1.69149 Validation Accuracy: 0.3656\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 1.6798 Accuracy: 0.407216 Validation Loss: 1.66983 Validation Accuracy: 0.3762\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss: 1.70411 Accuracy: 0.363402 Validation Loss: 1.68228 Validation Accuracy: 0.379\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss: 1.6319 Accuracy: 0.402062 Validation Loss: 1.66155 Validation Accuracy: 0.3816\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss: 1.65932 Accuracy: 0.393041 Validation Loss: 1.67613 Validation Accuracy: 0.3812\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss: 1.69583 Accuracy: 0.376289 Validation Loss: 1.64368 Validation Accuracy: 0.3924\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 1.62439 Accuracy: 0.42268 Validation Loss: 1.62806 Validation Accuracy: 0.401\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss: 1.66446 Accuracy: 0.381443 Validation Loss: 1.64607 Validation Accuracy: 0.4016\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss: 1.57207 Accuracy: 0.438144 Validation Loss: 1.60437 Validation Accuracy: 0.4116\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss: 1.58407 Accuracy: 0.423969 Validation Loss: 1.60321 Validation Accuracy: 0.4126\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss: 1.65695 Accuracy: 0.411082 Validation Loss: 1.59861 Validation Accuracy: 0.4168\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 1.59171 Accuracy: 0.448454 Validation Loss: 1.59963 Validation Accuracy: 0.4204\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss: 1.61086 Accuracy: 0.416237 Validation Loss: 1.57344 Validation Accuracy: 0.427\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss: 1.52565 Accuracy: 0.45232 Validation Loss: 1.56965 Validation Accuracy: 0.4286\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss: 1.54633 Accuracy: 0.435567 Validation Loss: 1.57084 Validation Accuracy: 0.419\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss: 1.62214 Accuracy: 0.41366 Validation Loss: 1.56868 Validation Accuracy: 0.4244\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 1.54613 Accuracy: 0.451031 Validation Loss: 1.55433 Validation Accuracy: 0.4312\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss: 1.57921 Accuracy: 0.426546 Validation Loss: 1.55038 Validation Accuracy: 0.434\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss: 1.49354 Accuracy: 0.449742 Validation Loss: 1.54303 Validation Accuracy: 0.4352\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss: 1.51015 Accuracy: 0.445876 Validation Loss: 1.54023 Validation Accuracy: 0.4338\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss: 1.58084 Accuracy: 0.423969 Validation Loss: 1.53744 Validation Accuracy: 0.4364\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 1.51321 Accuracy: 0.470361 Validation Loss: 1.52921 Validation Accuracy: 0.4368\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss: 1.55266 Accuracy: 0.434278 Validation Loss: 1.52754 Validation Accuracy: 0.4418\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss: 1.47375 Accuracy: 0.458763 Validation Loss: 1.52608 Validation Accuracy: 0.438\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss: 1.48934 Accuracy: 0.449742 Validation Loss: 1.52122 Validation Accuracy: 0.4452\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss: 1.57315 Accuracy: 0.431701 Validation Loss: 1.53372 Validation Accuracy: 0.4288\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 1.47914 Accuracy: 0.476804 Validation Loss: 1.50232 Validation Accuracy: 0.447\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss: 1.53395 Accuracy: 0.447165 Validation Loss: 1.51515 Validation Accuracy: 0.4442\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss: 1.43975 Accuracy: 0.474227 Validation Loss: 1.49833 Validation Accuracy: 0.4488\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss: 1.47596 Accuracy: 0.465206 Validation Loss: 1.51296 Validation Accuracy: 0.4444\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss: 1.54234 Accuracy: 0.457474 Validation Loss: 1.50115 Validation Accuracy: 0.449\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 1.47296 Accuracy: 0.484536 Validation Loss: 1.50128 Validation Accuracy: 0.4442\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss: 1.50758 Accuracy: 0.462629 Validation Loss: 1.50084 Validation Accuracy: 0.4532\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss: 1.42517 Accuracy: 0.475515 Validation Loss: 1.47774 Validation Accuracy: 0.456\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss: 1.43626 Accuracy: 0.457474 Validation Loss: 1.47995 Validation Accuracy: 0.4522\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss: 1.51511 Accuracy: 0.462629 Validation Loss: 1.48047 Validation Accuracy: 0.4552\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 1.44047 Accuracy: 0.485825 Validation Loss: 1.47738 Validation Accuracy: 0.4532\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss: 1.48273 Accuracy: 0.467783 Validation Loss: 1.47563 Validation Accuracy: 0.4606\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss: 1.40079 Accuracy: 0.488402 Validation Loss: 1.4617 Validation Accuracy: 0.4602\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss: 1.42047 Accuracy: 0.467783 Validation Loss: 1.46466 Validation Accuracy: 0.4588\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss: 1.50173 Accuracy: 0.470361 Validation Loss: 1.4739 Validation Accuracy: 0.4602\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 1.41662 Accuracy: 0.511598 Validation Loss: 1.45847 Validation Accuracy: 0.4646\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss: 1.46605 Accuracy: 0.471649 Validation Loss: 1.47047 Validation Accuracy: 0.4616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, CIFAR-10 Batch 3:  Loss: 1.38705 Accuracy: 0.490979 Validation Loss: 1.45585 Validation Accuracy: 0.4658\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss: 1.40827 Accuracy: 0.489691 Validation Loss: 1.4561 Validation Accuracy: 0.465\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss: 1.48462 Accuracy: 0.474227 Validation Loss: 1.4565 Validation Accuracy: 0.4696\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 1.39902 Accuracy: 0.506443 Validation Loss: 1.44734 Validation Accuracy: 0.4664\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss: 1.44083 Accuracy: 0.488402 Validation Loss: 1.44506 Validation Accuracy: 0.4682\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss: 1.36395 Accuracy: 0.503866 Validation Loss: 1.43469 Validation Accuracy: 0.468\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss: 1.37424 Accuracy: 0.490979 Validation Loss: 1.43202 Validation Accuracy: 0.4704\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss: 1.46804 Accuracy: 0.470361 Validation Loss: 1.44625 Validation Accuracy: 0.4678\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 1.3791 Accuracy: 0.510309 Validation Loss: 1.43366 Validation Accuracy: 0.4708\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss: 1.42529 Accuracy: 0.485825 Validation Loss: 1.42947 Validation Accuracy: 0.4706\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss: 1.35045 Accuracy: 0.527062 Validation Loss: 1.42573 Validation Accuracy: 0.4734\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss: 1.35721 Accuracy: 0.5 Validation Loss: 1.41877 Validation Accuracy: 0.4796\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss: 1.44816 Accuracy: 0.481959 Validation Loss: 1.43798 Validation Accuracy: 0.4732\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 1.36771 Accuracy: 0.51933 Validation Loss: 1.41808 Validation Accuracy: 0.4758\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss: 1.4161 Accuracy: 0.484536 Validation Loss: 1.41703 Validation Accuracy: 0.4742\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss: 1.32793 Accuracy: 0.51933 Validation Loss: 1.40651 Validation Accuracy: 0.4788\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss: 1.34019 Accuracy: 0.511598 Validation Loss: 1.40561 Validation Accuracy: 0.4828\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss: 1.42941 Accuracy: 0.489691 Validation Loss: 1.41719 Validation Accuracy: 0.4796\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 1.3516 Accuracy: 0.518041 Validation Loss: 1.41408 Validation Accuracy: 0.4748\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss: 1.40591 Accuracy: 0.496134 Validation Loss: 1.42079 Validation Accuracy: 0.4704\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss: 1.31555 Accuracy: 0.523196 Validation Loss: 1.39442 Validation Accuracy: 0.485\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss: 1.33168 Accuracy: 0.518041 Validation Loss: 1.39545 Validation Accuracy: 0.4852\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss: 1.41466 Accuracy: 0.501289 Validation Loss: 1.40673 Validation Accuracy: 0.4836\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 1.33624 Accuracy: 0.521907 Validation Loss: 1.39783 Validation Accuracy: 0.482\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss: 1.39019 Accuracy: 0.490979 Validation Loss: 1.39678 Validation Accuracy: 0.4866\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss: 1.30003 Accuracy: 0.52835 Validation Loss: 1.3799 Validation Accuracy: 0.4928\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss: 1.30901 Accuracy: 0.518041 Validation Loss: 1.38107 Validation Accuracy: 0.4936\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss: 1.40127 Accuracy: 0.507732 Validation Loss: 1.39079 Validation Accuracy: 0.4878\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 1.31691 Accuracy: 0.54768 Validation Loss: 1.37956 Validation Accuracy: 0.4868\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss: 1.37881 Accuracy: 0.498711 Validation Loss: 1.39702 Validation Accuracy: 0.4842\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss: 1.2926 Accuracy: 0.534794 Validation Loss: 1.37572 Validation Accuracy: 0.4876\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss: 1.29885 Accuracy: 0.523196 Validation Loss: 1.37399 Validation Accuracy: 0.4932\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss: 1.39037 Accuracy: 0.506443 Validation Loss: 1.38555 Validation Accuracy: 0.4902\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss: 1.31067 Accuracy: 0.543814 Validation Loss: 1.36706 Validation Accuracy: 0.4934\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss: 1.36611 Accuracy: 0.496134 Validation Loss: 1.38327 Validation Accuracy: 0.487\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss: 1.28646 Accuracy: 0.537371 Validation Loss: 1.37039 Validation Accuracy: 0.4922\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss: 1.30318 Accuracy: 0.524485 Validation Loss: 1.37719 Validation Accuracy: 0.4964\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss: 1.38155 Accuracy: 0.514175 Validation Loss: 1.37458 Validation Accuracy: 0.4938\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss: 1.30729 Accuracy: 0.52835 Validation Loss: 1.36866 Validation Accuracy: 0.4902\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss: 1.36254 Accuracy: 0.494845 Validation Loss: 1.38018 Validation Accuracy: 0.4928\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss: 1.28297 Accuracy: 0.53866 Validation Loss: 1.37303 Validation Accuracy: 0.4964\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss: 1.2916 Accuracy: 0.533505 Validation Loss: 1.36932 Validation Accuracy: 0.4922\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss: 1.37622 Accuracy: 0.512887 Validation Loss: 1.36634 Validation Accuracy: 0.4964\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss: 1.29991 Accuracy: 0.554124 Validation Loss: 1.35928 Validation Accuracy: 0.4946\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss: 1.34263 Accuracy: 0.509021 Validation Loss: 1.36698 Validation Accuracy: 0.4968\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss: 1.26069 Accuracy: 0.541237 Validation Loss: 1.35039 Validation Accuracy: 0.5014\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss: 1.27472 Accuracy: 0.542526 Validation Loss: 1.35642 Validation Accuracy: 0.5014\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss: 1.36072 Accuracy: 0.514175 Validation Loss: 1.35114 Validation Accuracy: 0.5022\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss: 1.28284 Accuracy: 0.559278 Validation Loss: 1.34668 Validation Accuracy: 0.4984\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss: 1.33209 Accuracy: 0.518041 Validation Loss: 1.36155 Validation Accuracy: 0.4972\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss: 1.25151 Accuracy: 0.533505 Validation Loss: 1.35088 Validation Accuracy: 0.5014\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss: 1.25842 Accuracy: 0.551546 Validation Loss: 1.34442 Validation Accuracy: 0.5068\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss: 1.35015 Accuracy: 0.516753 Validation Loss: 1.34364 Validation Accuracy: 0.5056\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss: 1.2717 Accuracy: 0.55799 Validation Loss: 1.3452 Validation Accuracy: 0.4976\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss: 1.32471 Accuracy: 0.521907 Validation Loss: 1.36446 Validation Accuracy: 0.5052\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss: 1.25723 Accuracy: 0.527062 Validation Loss: 1.35996 Validation Accuracy: 0.502\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss: 1.25826 Accuracy: 0.54768 Validation Loss: 1.34851 Validation Accuracy: 0.5024\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss: 1.34517 Accuracy: 0.523196 Validation Loss: 1.34326 Validation Accuracy: 0.5066\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss: 1.26454 Accuracy: 0.550258 Validation Loss: 1.33633 Validation Accuracy: 0.5038\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss: 1.30725 Accuracy: 0.521907 Validation Loss: 1.33933 Validation Accuracy: 0.5112\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss: 1.241 Accuracy: 0.537371 Validation Loss: 1.34717 Validation Accuracy: 0.5032\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss: 1.23805 Accuracy: 0.560567 Validation Loss: 1.33072 Validation Accuracy: 0.5112\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss: 1.32961 Accuracy: 0.537371 Validation Loss: 1.33432 Validation Accuracy: 0.5098\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss: 1.25236 Accuracy: 0.560567 Validation Loss: 1.33172 Validation Accuracy: 0.5066\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss: 1.30176 Accuracy: 0.525773 Validation Loss: 1.33857 Validation Accuracy: 0.5078\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss: 1.22819 Accuracy: 0.541237 Validation Loss: 1.33289 Validation Accuracy: 0.5124\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss: 1.2241 Accuracy: 0.56701 Validation Loss: 1.32634 Validation Accuracy: 0.5126\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss: 1.30889 Accuracy: 0.543814 Validation Loss: 1.32143 Validation Accuracy: 0.5156\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss: 1.24717 Accuracy: 0.560567 Validation Loss: 1.32966 Validation Accuracy: 0.508\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss: 1.28866 Accuracy: 0.534794 Validation Loss: 1.32508 Validation Accuracy: 0.512\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss: 1.21402 Accuracy: 0.569588 Validation Loss: 1.31876 Validation Accuracy: 0.5142\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss: 1.2128 Accuracy: 0.563144 Validation Loss: 1.3253 Validation Accuracy: 0.5162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, CIFAR-10 Batch 5:  Loss: 1.30053 Accuracy: 0.54768 Validation Loss: 1.31411 Validation Accuracy: 0.5184\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss: 1.25647 Accuracy: 0.550258 Validation Loss: 1.34598 Validation Accuracy: 0.5006\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss: 1.29391 Accuracy: 0.524485 Validation Loss: 1.32453 Validation Accuracy: 0.5122\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss: 1.21973 Accuracy: 0.559278 Validation Loss: 1.32154 Validation Accuracy: 0.5176\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss: 1.21485 Accuracy: 0.579897 Validation Loss: 1.32422 Validation Accuracy: 0.5188\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss: 1.2954 Accuracy: 0.545103 Validation Loss: 1.31109 Validation Accuracy: 0.5168\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss: 1.23457 Accuracy: 0.559278 Validation Loss: 1.32259 Validation Accuracy: 0.5076\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss: 1.27692 Accuracy: 0.532216 Validation Loss: 1.30509 Validation Accuracy: 0.5206\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss: 1.20505 Accuracy: 0.556701 Validation Loss: 1.30971 Validation Accuracy: 0.5246\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss: 1.19089 Accuracy: 0.574742 Validation Loss: 1.30545 Validation Accuracy: 0.521\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss: 1.28194 Accuracy: 0.550258 Validation Loss: 1.30184 Validation Accuracy: 0.522\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss: 1.21696 Accuracy: 0.573454 Validation Loss: 1.30754 Validation Accuracy: 0.511\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss: 1.26713 Accuracy: 0.533505 Validation Loss: 1.30887 Validation Accuracy: 0.522\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss: 1.18768 Accuracy: 0.561856 Validation Loss: 1.29995 Validation Accuracy: 0.5224\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss: 1.18612 Accuracy: 0.582474 Validation Loss: 1.30176 Validation Accuracy: 0.5254\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss: 1.26956 Accuracy: 0.565722 Validation Loss: 1.29738 Validation Accuracy: 0.5262\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss: 1.20566 Accuracy: 0.576031 Validation Loss: 1.30112 Validation Accuracy: 0.5202\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss: 1.25745 Accuracy: 0.545103 Validation Loss: 1.30472 Validation Accuracy: 0.524\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss: 1.20036 Accuracy: 0.552835 Validation Loss: 1.31492 Validation Accuracy: 0.5188\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss: 1.18516 Accuracy: 0.582474 Validation Loss: 1.30094 Validation Accuracy: 0.524\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss: 1.2682 Accuracy: 0.565722 Validation Loss: 1.29717 Validation Accuracy: 0.5258\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss: 1.2073 Accuracy: 0.572165 Validation Loss: 1.30009 Validation Accuracy: 0.5166\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss: 1.25166 Accuracy: 0.536082 Validation Loss: 1.30684 Validation Accuracy: 0.5244\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss: 1.17096 Accuracy: 0.565722 Validation Loss: 1.28349 Validation Accuracy: 0.5296\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss: 1.16322 Accuracy: 0.582474 Validation Loss: 1.28502 Validation Accuracy: 0.5316\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss: 1.25414 Accuracy: 0.568299 Validation Loss: 1.28971 Validation Accuracy: 0.5276\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss: 1.1834 Accuracy: 0.585051 Validation Loss: 1.28633 Validation Accuracy: 0.5254\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss: 1.23993 Accuracy: 0.550258 Validation Loss: 1.304 Validation Accuracy: 0.5226\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss: 1.16599 Accuracy: 0.568299 Validation Loss: 1.28117 Validation Accuracy: 0.528\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss: 1.15408 Accuracy: 0.591495 Validation Loss: 1.28491 Validation Accuracy: 0.5268\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss: 1.24017 Accuracy: 0.56701 Validation Loss: 1.27768 Validation Accuracy: 0.5284\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss: 1.17906 Accuracy: 0.595361 Validation Loss: 1.28776 Validation Accuracy: 0.5282\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss: 1.23154 Accuracy: 0.555412 Validation Loss: 1.29799 Validation Accuracy: 0.5254\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss: 1.15821 Accuracy: 0.570876 Validation Loss: 1.27515 Validation Accuracy: 0.5346\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss: 1.15527 Accuracy: 0.585051 Validation Loss: 1.28337 Validation Accuracy: 0.5308\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss: 1.23327 Accuracy: 0.570876 Validation Loss: 1.27368 Validation Accuracy: 0.5314\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss: 1.17708 Accuracy: 0.590206 Validation Loss: 1.28545 Validation Accuracy: 0.5304\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss: 1.2203 Accuracy: 0.559278 Validation Loss: 1.28806 Validation Accuracy: 0.5296\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss: 1.14523 Accuracy: 0.576031 Validation Loss: 1.26473 Validation Accuracy: 0.5336\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss: 1.13471 Accuracy: 0.591495 Validation Loss: 1.27438 Validation Accuracy: 0.5294\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss: 1.22628 Accuracy: 0.573453 Validation Loss: 1.27086 Validation Accuracy: 0.532\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss: 1.17581 Accuracy: 0.587629 Validation Loss: 1.28675 Validation Accuracy: 0.5334\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss: 1.21006 Accuracy: 0.559278 Validation Loss: 1.28346 Validation Accuracy: 0.5346\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss: 1.1433 Accuracy: 0.568299 Validation Loss: 1.26371 Validation Accuracy: 0.5368\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss: 1.12897 Accuracy: 0.596649 Validation Loss: 1.26656 Validation Accuracy: 0.5374\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss: 1.21803 Accuracy: 0.576031 Validation Loss: 1.26675 Validation Accuracy: 0.5378\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss: 1.15618 Accuracy: 0.600515 Validation Loss: 1.26575 Validation Accuracy: 0.5388\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss: 1.19842 Accuracy: 0.572165 Validation Loss: 1.27796 Validation Accuracy: 0.5352\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss: 1.13397 Accuracy: 0.576031 Validation Loss: 1.2624 Validation Accuracy: 0.5444\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss: 1.12618 Accuracy: 0.60567 Validation Loss: 1.27034 Validation Accuracy: 0.537\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss: 1.21027 Accuracy: 0.579897 Validation Loss: 1.26258 Validation Accuracy: 0.5376\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss: 1.14537 Accuracy: 0.606959 Validation Loss: 1.26033 Validation Accuracy: 0.5414\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss: 1.18813 Accuracy: 0.570876 Validation Loss: 1.27176 Validation Accuracy: 0.5374\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss: 1.12545 Accuracy: 0.582474 Validation Loss: 1.25184 Validation Accuracy: 0.541\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss: 1.11142 Accuracy: 0.610825 Validation Loss: 1.25427 Validation Accuracy: 0.5416\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss: 1.20378 Accuracy: 0.582474 Validation Loss: 1.25947 Validation Accuracy: 0.5386\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss: 1.13701 Accuracy: 0.604381 Validation Loss: 1.25339 Validation Accuracy: 0.5448\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss: 1.17592 Accuracy: 0.576031 Validation Loss: 1.2668 Validation Accuracy: 0.5416\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss: 1.11439 Accuracy: 0.578608 Validation Loss: 1.24985 Validation Accuracy: 0.5454\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss: 1.10302 Accuracy: 0.613402 Validation Loss: 1.25458 Validation Accuracy: 0.5432\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss: 1.19421 Accuracy: 0.587629 Validation Loss: 1.25415 Validation Accuracy: 0.5412\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss: 1.13012 Accuracy: 0.612113 Validation Loss: 1.2497 Validation Accuracy: 0.5428\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss: 1.16673 Accuracy: 0.576031 Validation Loss: 1.26018 Validation Accuracy: 0.5434\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss: 1.11243 Accuracy: 0.57732 Validation Loss: 1.24553 Validation Accuracy: 0.5464\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss: 1.09647 Accuracy: 0.617268 Validation Loss: 1.24837 Validation Accuracy: 0.5432\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss: 1.18591 Accuracy: 0.588917 Validation Loss: 1.24975 Validation Accuracy: 0.5472\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss: 1.11805 Accuracy: 0.610825 Validation Loss: 1.24372 Validation Accuracy: 0.5512\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss: 1.15415 Accuracy: 0.579897 Validation Loss: 1.25016 Validation Accuracy: 0.5454\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss: 1.10803 Accuracy: 0.588917 Validation Loss: 1.24639 Validation Accuracy: 0.5494\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss: 1.0834 Accuracy: 0.626289 Validation Loss: 1.24662 Validation Accuracy: 0.541\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss: 1.17299 Accuracy: 0.590206 Validation Loss: 1.24093 Validation Accuracy: 0.551\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss: 1.11436 Accuracy: 0.608247 Validation Loss: 1.24154 Validation Accuracy: 0.5554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, CIFAR-10 Batch 2:  Loss: 1.1419 Accuracy: 0.582474 Validation Loss: 1.24462 Validation Accuracy: 0.5528\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss: 1.09443 Accuracy: 0.585051 Validation Loss: 1.23562 Validation Accuracy: 0.5516\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss: 1.07121 Accuracy: 0.621134 Validation Loss: 1.2353 Validation Accuracy: 0.5486\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss: 1.15896 Accuracy: 0.588917 Validation Loss: 1.23417 Validation Accuracy: 0.5568\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss: 1.10539 Accuracy: 0.608247 Validation Loss: 1.23734 Validation Accuracy: 0.5554\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss: 1.12837 Accuracy: 0.597938 Validation Loss: 1.23374 Validation Accuracy: 0.5568\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss: 1.09137 Accuracy: 0.592783 Validation Loss: 1.23478 Validation Accuracy: 0.5504\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss: 1.06941 Accuracy: 0.637887 Validation Loss: 1.2393 Validation Accuracy: 0.5468\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss: 1.14754 Accuracy: 0.601804 Validation Loss: 1.22562 Validation Accuracy: 0.5552\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss: 1.10358 Accuracy: 0.615979 Validation Loss: 1.23787 Validation Accuracy: 0.5564\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss: 1.12351 Accuracy: 0.599227 Validation Loss: 1.23342 Validation Accuracy: 0.5556\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss: 1.07217 Accuracy: 0.601804 Validation Loss: 1.2172 Validation Accuracy: 0.5576\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss: 1.05008 Accuracy: 0.622423 Validation Loss: 1.2229 Validation Accuracy: 0.556\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss: 1.13514 Accuracy: 0.614691 Validation Loss: 1.21888 Validation Accuracy: 0.5592\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss: 1.08208 Accuracy: 0.625 Validation Loss: 1.22653 Validation Accuracy: 0.5534\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss: 1.10794 Accuracy: 0.600515 Validation Loss: 1.22543 Validation Accuracy: 0.5578\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss: 1.06482 Accuracy: 0.614691 Validation Loss: 1.21819 Validation Accuracy: 0.5538\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss: 1.04557 Accuracy: 0.626289 Validation Loss: 1.22044 Validation Accuracy: 0.5518\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss: 1.12659 Accuracy: 0.612113 Validation Loss: 1.2139 Validation Accuracy: 0.561\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss: 1.06951 Accuracy: 0.626289 Validation Loss: 1.21685 Validation Accuracy: 0.56\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss: 1.09862 Accuracy: 0.619845 Validation Loss: 1.22075 Validation Accuracy: 0.559\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss: 1.06408 Accuracy: 0.608247 Validation Loss: 1.21803 Validation Accuracy: 0.5578\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss: 1.03536 Accuracy: 0.631443 Validation Loss: 1.21235 Validation Accuracy: 0.5586\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss: 1.11993 Accuracy: 0.613402 Validation Loss: 1.21235 Validation Accuracy: 0.561\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss: 1.05689 Accuracy: 0.626289 Validation Loss: 1.20927 Validation Accuracy: 0.5612\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss: 1.11448 Accuracy: 0.604381 Validation Loss: 1.24638 Validation Accuracy: 0.5546\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss: 1.0622 Accuracy: 0.60567 Validation Loss: 1.22377 Validation Accuracy: 0.5606\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss: 1.03958 Accuracy: 0.634021 Validation Loss: 1.21845 Validation Accuracy: 0.5554\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss: 1.10744 Accuracy: 0.625 Validation Loss: 1.20212 Validation Accuracy: 0.5634\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss: 1.0575 Accuracy: 0.636598 Validation Loss: 1.21491 Validation Accuracy: 0.5638\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss: 1.08501 Accuracy: 0.610825 Validation Loss: 1.21508 Validation Accuracy: 0.5596\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss: 1.0415 Accuracy: 0.618557 Validation Loss: 1.20797 Validation Accuracy: 0.562\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss: 1.02591 Accuracy: 0.64433 Validation Loss: 1.21835 Validation Accuracy: 0.5532\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss: 1.10034 Accuracy: 0.622423 Validation Loss: 1.20024 Validation Accuracy: 0.5642\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss: 1.04327 Accuracy: 0.639175 Validation Loss: 1.20094 Validation Accuracy: 0.5662\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss: 1.06963 Accuracy: 0.615979 Validation Loss: 1.20663 Validation Accuracy: 0.5678\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss: 1.03214 Accuracy: 0.619845 Validation Loss: 1.20079 Validation Accuracy: 0.5642\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss: 1.0104 Accuracy: 0.636598 Validation Loss: 1.20552 Validation Accuracy: 0.561\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss: 1.08631 Accuracy: 0.635309 Validation Loss: 1.19625 Validation Accuracy: 0.569\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss: 1.03585 Accuracy: 0.650773 Validation Loss: 1.20101 Validation Accuracy: 0.5694\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss: 1.06223 Accuracy: 0.621134 Validation Loss: 1.20301 Validation Accuracy: 0.5642\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss: 1.0292 Accuracy: 0.630155 Validation Loss: 1.20128 Validation Accuracy: 0.5654\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss: 1.03071 Accuracy: 0.634021 Validation Loss: 1.23101 Validation Accuracy: 0.5474\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss: 1.08298 Accuracy: 0.628866 Validation Loss: 1.19375 Validation Accuracy: 0.5662\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss: 1.02795 Accuracy: 0.639175 Validation Loss: 1.19401 Validation Accuracy: 0.5702\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss: 1.06276 Accuracy: 0.618557 Validation Loss: 1.2 Validation Accuracy: 0.569\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss: 1.04762 Accuracy: 0.597938 Validation Loss: 1.22082 Validation Accuracy: 0.5576\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss: 1.01005 Accuracy: 0.649485 Validation Loss: 1.20762 Validation Accuracy: 0.5606\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss: 1.06863 Accuracy: 0.634021 Validation Loss: 1.18894 Validation Accuracy: 0.5754\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss: 1.02043 Accuracy: 0.654639 Validation Loss: 1.18823 Validation Accuracy: 0.5718\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss: 1.05078 Accuracy: 0.623711 Validation Loss: 1.19685 Validation Accuracy: 0.5696\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss: 1.01229 Accuracy: 0.639175 Validation Loss: 1.18381 Validation Accuracy: 0.5694\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss: 0.98857 Accuracy: 0.65335 Validation Loss: 1.18916 Validation Accuracy: 0.5706\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss: 1.05623 Accuracy: 0.639175 Validation Loss: 1.18292 Validation Accuracy: 0.5728\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss: 1.01768 Accuracy: 0.646907 Validation Loss: 1.19182 Validation Accuracy: 0.5652\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss: 1.03878 Accuracy: 0.628866 Validation Loss: 1.18943 Validation Accuracy: 0.5706\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss: 1.01241 Accuracy: 0.635309 Validation Loss: 1.19199 Validation Accuracy: 0.5678\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss: 0.985347 Accuracy: 0.650773 Validation Loss: 1.18796 Validation Accuracy: 0.5722\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss: 1.0461 Accuracy: 0.646907 Validation Loss: 1.18059 Validation Accuracy: 0.572\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss: 1.00308 Accuracy: 0.648196 Validation Loss: 1.17904 Validation Accuracy: 0.5736\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss: 1.0286 Accuracy: 0.628866 Validation Loss: 1.18188 Validation Accuracy: 0.5742\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss: 1.00405 Accuracy: 0.632732 Validation Loss: 1.18695 Validation Accuracy: 0.5668\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss: 0.977403 Accuracy: 0.658505 Validation Loss: 1.18195 Validation Accuracy: 0.5712\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss: 1.03823 Accuracy: 0.648196 Validation Loss: 1.18029 Validation Accuracy: 0.5736\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss: 0.999357 Accuracy: 0.66366 Validation Loss: 1.17961 Validation Accuracy: 0.5698\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss: 1.03223 Accuracy: 0.635309 Validation Loss: 1.18571 Validation Accuracy: 0.5768\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss: 0.994236 Accuracy: 0.643041 Validation Loss: 1.17812 Validation Accuracy: 0.5696\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss: 0.971327 Accuracy: 0.661082 Validation Loss: 1.1813 Validation Accuracy: 0.5758\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss: 1.03532 Accuracy: 0.643041 Validation Loss: 1.17963 Validation Accuracy: 0.572\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss: 0.991896 Accuracy: 0.670103 Validation Loss: 1.17716 Validation Accuracy: 0.5728\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss: 1.00611 Accuracy: 0.632732 Validation Loss: 1.17485 Validation Accuracy: 0.5762\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss: 0.981968 Accuracy: 0.649484 Validation Loss: 1.17326 Validation Accuracy: 0.5766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58, CIFAR-10 Batch 4:  Loss: 0.966327 Accuracy: 0.662371 Validation Loss: 1.18427 Validation Accuracy: 0.5736\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss: 1.0325 Accuracy: 0.645618 Validation Loss: 1.18453 Validation Accuracy: 0.5722\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss: 0.979685 Accuracy: 0.662371 Validation Loss: 1.17524 Validation Accuracy: 0.5774\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss: 1.00222 Accuracy: 0.635309 Validation Loss: 1.1734 Validation Accuracy: 0.577\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss: 0.982692 Accuracy: 0.641753 Validation Loss: 1.17619 Validation Accuracy: 0.5708\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss: 0.961506 Accuracy: 0.66366 Validation Loss: 1.18258 Validation Accuracy: 0.5724\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss: 1.01527 Accuracy: 0.648196 Validation Loss: 1.17445 Validation Accuracy: 0.5768\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss: 0.966525 Accuracy: 0.658505 Validation Loss: 1.16461 Validation Accuracy: 0.5784\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss: 0.989965 Accuracy: 0.646907 Validation Loss: 1.17399 Validation Accuracy: 0.5774\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss: 0.981676 Accuracy: 0.645618 Validation Loss: 1.18368 Validation Accuracy: 0.5716\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss: 0.970135 Accuracy: 0.65335 Validation Loss: 1.2022 Validation Accuracy: 0.5642\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss: 1.00961 Accuracy: 0.654639 Validation Loss: 1.17984 Validation Accuracy: 0.5748\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss: 0.985246 Accuracy: 0.655928 Validation Loss: 1.1853 Validation Accuracy: 0.5752\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss: 1.01832 Accuracy: 0.623711 Validation Loss: 1.21469 Validation Accuracy: 0.5618\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss: 0.990323 Accuracy: 0.643041 Validation Loss: 1.20724 Validation Accuracy: 0.5656\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss: 1.01713 Accuracy: 0.657216 Validation Loss: 1.26774 Validation Accuracy: 0.547\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss: 1.0295 Accuracy: 0.658505 Validation Loss: 1.19761 Validation Accuracy: 0.5676\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss: 0.981646 Accuracy: 0.673969 Validation Loss: 1.16944 Validation Accuracy: 0.5738\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss: 0.998763 Accuracy: 0.634021 Validation Loss: 1.18395 Validation Accuracy: 0.5782\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss: 0.979572 Accuracy: 0.635309 Validation Loss: 1.18097 Validation Accuracy: 0.5702\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss: 0.938987 Accuracy: 0.677835 Validation Loss: 1.17016 Validation Accuracy: 0.5774\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss: 0.987536 Accuracy: 0.677835 Validation Loss: 1.16039 Validation Accuracy: 0.5824\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss: 0.95717 Accuracy: 0.677835 Validation Loss: 1.16113 Validation Accuracy: 0.5794\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss: 0.986934 Accuracy: 0.649485 Validation Loss: 1.1802 Validation Accuracy: 0.5806\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss: 0.958594 Accuracy: 0.654639 Validation Loss: 1.17037 Validation Accuracy: 0.5754\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss: 0.943341 Accuracy: 0.676546 Validation Loss: 1.18262 Validation Accuracy: 0.5736\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss: 0.982515 Accuracy: 0.671392 Validation Loss: 1.16122 Validation Accuracy: 0.5854\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss: 0.951693 Accuracy: 0.675258 Validation Loss: 1.16022 Validation Accuracy: 0.5794\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss: 0.966735 Accuracy: 0.666237 Validation Loss: 1.16274 Validation Accuracy: 0.5818\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss: 0.948461 Accuracy: 0.658505 Validation Loss: 1.17008 Validation Accuracy: 0.5746\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss: 0.932484 Accuracy: 0.676546 Validation Loss: 1.17781 Validation Accuracy: 0.5762\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss: 0.971718 Accuracy: 0.67268 Validation Loss: 1.15674 Validation Accuracy: 0.5816\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss: 0.940895 Accuracy: 0.677835 Validation Loss: 1.15054 Validation Accuracy: 0.582\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss: 0.959399 Accuracy: 0.664948 Validation Loss: 1.16417 Validation Accuracy: 0.5812\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss: 0.936373 Accuracy: 0.658505 Validation Loss: 1.15923 Validation Accuracy: 0.5808\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss: 0.928011 Accuracy: 0.688144 Validation Loss: 1.17859 Validation Accuracy: 0.5716\n",
      "Epoch 65, CIFAR-10 Batch 5:  Loss: 0.962666 Accuracy: 0.680412 Validation Loss: 1.15292 Validation Accuracy: 0.5874\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss: 0.961881 Accuracy: 0.657216 Validation Loss: 1.17651 Validation Accuracy: 0.5726\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss: 0.951191 Accuracy: 0.661082 Validation Loss: 1.15715 Validation Accuracy: 0.5838\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss: 0.92701 Accuracy: 0.680412 Validation Loss: 1.14863 Validation Accuracy: 0.5834\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss: 0.912199 Accuracy: 0.679124 Validation Loss: 1.16518 Validation Accuracy: 0.5802\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss: 0.96067 Accuracy: 0.677835 Validation Loss: 1.15519 Validation Accuracy: 0.5816\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss: 0.928338 Accuracy: 0.688144 Validation Loss: 1.15269 Validation Accuracy: 0.5862\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss: 0.943642 Accuracy: 0.677835 Validation Loss: 1.16006 Validation Accuracy: 0.5818\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss: 0.926844 Accuracy: 0.670103 Validation Loss: 1.16069 Validation Accuracy: 0.582\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss: 0.909486 Accuracy: 0.688144 Validation Loss: 1.17256 Validation Accuracy: 0.5806\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss: 0.953175 Accuracy: 0.68299 Validation Loss: 1.15717 Validation Accuracy: 0.5844\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss: 0.933879 Accuracy: 0.676546 Validation Loss: 1.15451 Validation Accuracy: 0.5822\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss: 0.93156 Accuracy: 0.673969 Validation Loss: 1.14925 Validation Accuracy: 0.586\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss: 0.907375 Accuracy: 0.681701 Validation Loss: 1.14021 Validation Accuracy: 0.5876\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss: 0.91189 Accuracy: 0.693299 Validation Loss: 1.17273 Validation Accuracy: 0.5786\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss: 0.943669 Accuracy: 0.688144 Validation Loss: 1.15212 Validation Accuracy: 0.5866\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss: 0.925762 Accuracy: 0.689433 Validation Loss: 1.14933 Validation Accuracy: 0.5808\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss: 0.938213 Accuracy: 0.668814 Validation Loss: 1.15583 Validation Accuracy: 0.5838\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss: 0.909365 Accuracy: 0.676546 Validation Loss: 1.1432 Validation Accuracy: 0.5868\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss: 0.899171 Accuracy: 0.690722 Validation Loss: 1.15689 Validation Accuracy: 0.5846\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss: 0.93016 Accuracy: 0.698453 Validation Loss: 1.14854 Validation Accuracy: 0.5868\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss: 0.915225 Accuracy: 0.684278 Validation Loss: 1.14942 Validation Accuracy: 0.5868\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss: 0.917491 Accuracy: 0.686856 Validation Loss: 1.14645 Validation Accuracy: 0.5864\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss: 0.916498 Accuracy: 0.675258 Validation Loss: 1.15763 Validation Accuracy: 0.5832\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss: 0.887717 Accuracy: 0.694588 Validation Loss: 1.15603 Validation Accuracy: 0.5842\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss: 0.923339 Accuracy: 0.699742 Validation Loss: 1.14382 Validation Accuracy: 0.5898\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss: 0.90975 Accuracy: 0.689433 Validation Loss: 1.14869 Validation Accuracy: 0.5854\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss: 0.912324 Accuracy: 0.684278 Validation Loss: 1.14748 Validation Accuracy: 0.587\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss: 0.893172 Accuracy: 0.68299 Validation Loss: 1.13802 Validation Accuracy: 0.5872\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss: 0.882933 Accuracy: 0.698454 Validation Loss: 1.1518 Validation Accuracy: 0.5854\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss: 0.924046 Accuracy: 0.695876 Validation Loss: 1.14714 Validation Accuracy: 0.5904\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss: 0.909257 Accuracy: 0.690722 Validation Loss: 1.14787 Validation Accuracy: 0.587\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss: 0.902034 Accuracy: 0.684278 Validation Loss: 1.13881 Validation Accuracy: 0.5888\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss: 0.883664 Accuracy: 0.677835 Validation Loss: 1.13418 Validation Accuracy: 0.59\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss: 0.881136 Accuracy: 0.699742 Validation Loss: 1.15143 Validation Accuracy: 0.5904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72, CIFAR-10 Batch 5:  Loss: 0.914227 Accuracy: 0.703608 Validation Loss: 1.14031 Validation Accuracy: 0.5928\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss: 0.894311 Accuracy: 0.693299 Validation Loss: 1.13587 Validation Accuracy: 0.5928\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss: 0.955675 Accuracy: 0.662371 Validation Loss: 1.19042 Validation Accuracy: 0.5742\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss: 0.910657 Accuracy: 0.668814 Validation Loss: 1.15864 Validation Accuracy: 0.5786\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss: 0.924724 Accuracy: 0.698454 Validation Loss: 1.18539 Validation Accuracy: 0.5798\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss: 0.929549 Accuracy: 0.695876 Validation Loss: 1.14987 Validation Accuracy: 0.5886\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss: 0.908979 Accuracy: 0.688144 Validation Loss: 1.14619 Validation Accuracy: 0.5926\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss: 0.898626 Accuracy: 0.680412 Validation Loss: 1.14191 Validation Accuracy: 0.593\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss: 0.877585 Accuracy: 0.68299 Validation Loss: 1.13609 Validation Accuracy: 0.5906\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss: 0.870938 Accuracy: 0.703608 Validation Loss: 1.15066 Validation Accuracy: 0.5902\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss: 0.905169 Accuracy: 0.699742 Validation Loss: 1.13727 Validation Accuracy: 0.5954\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss: 0.891425 Accuracy: 0.69201 Validation Loss: 1.13959 Validation Accuracy: 0.594\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss: 0.889956 Accuracy: 0.685567 Validation Loss: 1.13538 Validation Accuracy: 0.5934\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss: 0.870432 Accuracy: 0.695876 Validation Loss: 1.13337 Validation Accuracy: 0.5926\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss: 0.857934 Accuracy: 0.708763 Validation Loss: 1.13712 Validation Accuracy: 0.5946\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss: 0.893312 Accuracy: 0.710052 Validation Loss: 1.13865 Validation Accuracy: 0.5972\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss: 0.888541 Accuracy: 0.703608 Validation Loss: 1.14617 Validation Accuracy: 0.5898\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss: 0.874555 Accuracy: 0.708763 Validation Loss: 1.13344 Validation Accuracy: 0.5918\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss: 0.866984 Accuracy: 0.688144 Validation Loss: 1.13312 Validation Accuracy: 0.5912\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss: 0.862566 Accuracy: 0.70232 Validation Loss: 1.14612 Validation Accuracy: 0.591\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss: 0.890043 Accuracy: 0.710051 Validation Loss: 1.13318 Validation Accuracy: 0.5958\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss: 0.876163 Accuracy: 0.699742 Validation Loss: 1.13087 Validation Accuracy: 0.6002\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss: 0.915596 Accuracy: 0.664948 Validation Loss: 1.16981 Validation Accuracy: 0.5816\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss: 0.867507 Accuracy: 0.690722 Validation Loss: 1.13797 Validation Accuracy: 0.5916\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss: 0.863385 Accuracy: 0.717783 Validation Loss: 1.15002 Validation Accuracy: 0.5918\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss: 0.887059 Accuracy: 0.708763 Validation Loss: 1.13487 Validation Accuracy: 0.5936\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss: 0.868703 Accuracy: 0.698453 Validation Loss: 1.12958 Validation Accuracy: 0.5992\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss: 0.896216 Accuracy: 0.688144 Validation Loss: 1.14907 Validation Accuracy: 0.5918\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss: 0.891544 Accuracy: 0.680412 Validation Loss: 1.16502 Validation Accuracy: 0.577\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss: 0.856697 Accuracy: 0.712629 Validation Loss: 1.14996 Validation Accuracy: 0.5896\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss: 0.882196 Accuracy: 0.715206 Validation Loss: 1.13246 Validation Accuracy: 0.593\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss: 0.872291 Accuracy: 0.697165 Validation Loss: 1.13191 Validation Accuracy: 0.6004\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss: 0.864716 Accuracy: 0.698454 Validation Loss: 1.12807 Validation Accuracy: 0.5976\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss: 0.881971 Accuracy: 0.685567 Validation Loss: 1.1523 Validation Accuracy: 0.5866\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss: 0.865768 Accuracy: 0.708763 Validation Loss: 1.16467 Validation Accuracy: 0.5886\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss: 0.907226 Accuracy: 0.698454 Validation Loss: 1.16421 Validation Accuracy: 0.5846\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss: 0.891555 Accuracy: 0.695876 Validation Loss: 1.14992 Validation Accuracy: 0.5964\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss: 0.863771 Accuracy: 0.706186 Validation Loss: 1.12617 Validation Accuracy: 0.5934\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss: 0.846574 Accuracy: 0.71134 Validation Loss: 1.12793 Validation Accuracy: 0.6002\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss: 0.849792 Accuracy: 0.698453 Validation Loss: 1.15388 Validation Accuracy: 0.5926\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss: 0.871598 Accuracy: 0.71134 Validation Loss: 1.13894 Validation Accuracy: 0.598\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss: 0.895984 Accuracy: 0.704897 Validation Loss: 1.15813 Validation Accuracy: 0.5792\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss: 0.881885 Accuracy: 0.689433 Validation Loss: 1.14047 Validation Accuracy: 0.5962\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss: 0.880451 Accuracy: 0.685567 Validation Loss: 1.1578 Validation Accuracy: 0.5822\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss: 0.854689 Accuracy: 0.729381 Validation Loss: 1.15499 Validation Accuracy: 0.5874\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss: 0.880176 Accuracy: 0.699742 Validation Loss: 1.14476 Validation Accuracy: 0.5928\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss: 0.899421 Accuracy: 0.704897 Validation Loss: 1.15575 Validation Accuracy: 0.582\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss: 0.871082 Accuracy: 0.690722 Validation Loss: 1.13265 Validation Accuracy: 0.5934\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss: 0.837701 Accuracy: 0.717783 Validation Loss: 1.11889 Validation Accuracy: 0.5992\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss: 0.843084 Accuracy: 0.719072 Validation Loss: 1.14054 Validation Accuracy: 0.5958\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss: 0.864358 Accuracy: 0.715206 Validation Loss: 1.13352 Validation Accuracy: 0.5988\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss: 0.887604 Accuracy: 0.707474 Validation Loss: 1.14377 Validation Accuracy: 0.5912\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss: 0.890694 Accuracy: 0.699742 Validation Loss: 1.14574 Validation Accuracy: 0.5832\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss: 0.850856 Accuracy: 0.715206 Validation Loss: 1.13269 Validation Accuracy: 0.594\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss: 0.875604 Accuracy: 0.708763 Validation Loss: 1.17818 Validation Accuracy: 0.5856\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss: 0.8654 Accuracy: 0.717783 Validation Loss: 1.15027 Validation Accuracy: 0.5892\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss: 0.912641 Accuracy: 0.699742 Validation Loss: 1.16641 Validation Accuracy: 0.5804\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss: 0.91059 Accuracy: 0.673969 Validation Loss: 1.19537 Validation Accuracy: 0.5682\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss: 0.915869 Accuracy: 0.655928 Validation Loss: 1.20403 Validation Accuracy: 0.5704\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss: 0.877923 Accuracy: 0.698453 Validation Loss: 1.18105 Validation Accuracy: 0.577\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss: 0.895177 Accuracy: 0.698454 Validation Loss: 1.16527 Validation Accuracy: 0.5812\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss: 0.878972 Accuracy: 0.686856 Validation Loss: 1.13243 Validation Accuracy: 0.5926\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss: 0.900079 Accuracy: 0.694588 Validation Loss: 1.16047 Validation Accuracy: 0.5888\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss: 0.855279 Accuracy: 0.690722 Validation Loss: 1.13817 Validation Accuracy: 0.588\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss: 0.828699 Accuracy: 0.713917 Validation Loss: 1.12255 Validation Accuracy: 0.5986\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss: 0.84259 Accuracy: 0.722938 Validation Loss: 1.11746 Validation Accuracy: 0.6054\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss: 0.843396 Accuracy: 0.710051 Validation Loss: 1.12055 Validation Accuracy: 0.6014\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss: 0.849936 Accuracy: 0.715206 Validation Loss: 1.13259 Validation Accuracy: 0.5994\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss: 0.867958 Accuracy: 0.686856 Validation Loss: 1.15661 Validation Accuracy: 0.5848\n",
      "Epoch 86, CIFAR-10 Batch 4:  Loss: 0.822711 Accuracy: 0.722938 Validation Loss: 1.12172 Validation Accuracy: 0.6016\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss: 0.845186 Accuracy: 0.734536 Validation Loss: 1.11681 Validation Accuracy: 0.6026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87, CIFAR-10 Batch 1:  Loss: 0.837084 Accuracy: 0.702319 Validation Loss: 1.11594 Validation Accuracy: 0.6026\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss: 0.843789 Accuracy: 0.725515 Validation Loss: 1.11871 Validation Accuracy: 0.5982\n",
      "Epoch 87, CIFAR-10 Batch 3:  Loss: 0.836829 Accuracy: 0.703608 Validation Loss: 1.13334 Validation Accuracy: 0.5998\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss: 0.810315 Accuracy: 0.724227 Validation Loss: 1.11894 Validation Accuracy: 0.6038\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss: 0.827561 Accuracy: 0.737113 Validation Loss: 1.11194 Validation Accuracy: 0.6042\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss: 0.831021 Accuracy: 0.712629 Validation Loss: 1.11491 Validation Accuracy: 0.6044\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss: 0.833584 Accuracy: 0.722938 Validation Loss: 1.11567 Validation Accuracy: 0.6042\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss: 0.826365 Accuracy: 0.70232 Validation Loss: 1.12492 Validation Accuracy: 0.6024\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss: 0.809314 Accuracy: 0.73067 Validation Loss: 1.1162 Validation Accuracy: 0.6064\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss: 0.831243 Accuracy: 0.733247 Validation Loss: 1.11524 Validation Accuracy: 0.6028\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss: 0.842996 Accuracy: 0.717783 Validation Loss: 1.12168 Validation Accuracy: 0.6008\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss: 0.832944 Accuracy: 0.726804 Validation Loss: 1.11075 Validation Accuracy: 0.6078\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss: 0.832204 Accuracy: 0.70232 Validation Loss: 1.13108 Validation Accuracy: 0.6012\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss: 0.816236 Accuracy: 0.717783 Validation Loss: 1.12266 Validation Accuracy: 0.6046\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss: 0.825103 Accuracy: 0.739691 Validation Loss: 1.11413 Validation Accuracy: 0.6032\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss: 0.824734 Accuracy: 0.712629 Validation Loss: 1.11584 Validation Accuracy: 0.6058\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss: 0.828372 Accuracy: 0.724227 Validation Loss: 1.11771 Validation Accuracy: 0.6052\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss: 0.827811 Accuracy: 0.706185 Validation Loss: 1.12869 Validation Accuracy: 0.6028\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss: 0.806533 Accuracy: 0.729381 Validation Loss: 1.11722 Validation Accuracy: 0.608\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss: 0.818336 Accuracy: 0.740979 Validation Loss: 1.10744 Validation Accuracy: 0.608\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss: 0.818903 Accuracy: 0.71134 Validation Loss: 1.10901 Validation Accuracy: 0.6048\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss: 0.817778 Accuracy: 0.728093 Validation Loss: 1.11343 Validation Accuracy: 0.6066\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss: 0.817898 Accuracy: 0.715206 Validation Loss: 1.12956 Validation Accuracy: 0.6036\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss: 0.802322 Accuracy: 0.729381 Validation Loss: 1.12198 Validation Accuracy: 0.6026\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss: 0.815767 Accuracy: 0.739691 Validation Loss: 1.11013 Validation Accuracy: 0.6054\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss: 0.819847 Accuracy: 0.716495 Validation Loss: 1.11328 Validation Accuracy: 0.6038\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss: 0.816766 Accuracy: 0.731959 Validation Loss: 1.12013 Validation Accuracy: 0.6008\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss: 0.816082 Accuracy: 0.73067 Validation Loss: 1.1284 Validation Accuracy: 0.6028\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss: 0.793805 Accuracy: 0.726804 Validation Loss: 1.11843 Validation Accuracy: 0.602\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss: 0.811343 Accuracy: 0.738402 Validation Loss: 1.10978 Validation Accuracy: 0.6102\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss: 0.814928 Accuracy: 0.716495 Validation Loss: 1.10951 Validation Accuracy: 0.6064\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss: 0.81166 Accuracy: 0.739691 Validation Loss: 1.11761 Validation Accuracy: 0.6016\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss: 0.805745 Accuracy: 0.720361 Validation Loss: 1.11576 Validation Accuracy: 0.6024\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss: 0.78892 Accuracy: 0.742268 Validation Loss: 1.11431 Validation Accuracy: 0.6088\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss: 0.804912 Accuracy: 0.752577 Validation Loss: 1.10519 Validation Accuracy: 0.6064\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss: 0.806156 Accuracy: 0.715206 Validation Loss: 1.1108 Validation Accuracy: 0.6074\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss: 0.804548 Accuracy: 0.733247 Validation Loss: 1.10894 Validation Accuracy: 0.6072\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss: 0.795948 Accuracy: 0.731959 Validation Loss: 1.11622 Validation Accuracy: 0.6038\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss: 0.781146 Accuracy: 0.744845 Validation Loss: 1.11404 Validation Accuracy: 0.606\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss: 0.803671 Accuracy: 0.738402 Validation Loss: 1.11452 Validation Accuracy: 0.608\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss: 0.814736 Accuracy: 0.721649 Validation Loss: 1.11644 Validation Accuracy: 0.6074\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss: 0.799916 Accuracy: 0.737113 Validation Loss: 1.10579 Validation Accuracy: 0.6086\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss: 0.792536 Accuracy: 0.733247 Validation Loss: 1.11383 Validation Accuracy: 0.6042\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss: 0.777474 Accuracy: 0.738402 Validation Loss: 1.12004 Validation Accuracy: 0.605\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss: 0.802588 Accuracy: 0.73067 Validation Loss: 1.11836 Validation Accuracy: 0.6046\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss: 0.816282 Accuracy: 0.722938 Validation Loss: 1.12378 Validation Accuracy: 0.5992\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss: 0.799567 Accuracy: 0.726804 Validation Loss: 1.11183 Validation Accuracy: 0.6068\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss: 0.795533 Accuracy: 0.728093 Validation Loss: 1.11869 Validation Accuracy: 0.6026\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss: 0.771903 Accuracy: 0.747423 Validation Loss: 1.10953 Validation Accuracy: 0.608\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss: 0.791367 Accuracy: 0.737113 Validation Loss: 1.10932 Validation Accuracy: 0.6108\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss: 0.803192 Accuracy: 0.724227 Validation Loss: 1.10911 Validation Accuracy: 0.6088\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss: 0.795169 Accuracy: 0.735825 Validation Loss: 1.11347 Validation Accuracy: 0.6106\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss: 0.792917 Accuracy: 0.738402 Validation Loss: 1.12162 Validation Accuracy: 0.606\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss: 0.775528 Accuracy: 0.747423 Validation Loss: 1.11544 Validation Accuracy: 0.6068\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss: 0.794675 Accuracy: 0.739691 Validation Loss: 1.11689 Validation Accuracy: 0.603\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss: 0.789312 Accuracy: 0.726804 Validation Loss: 1.10534 Validation Accuracy: 0.6134\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss: 0.789551 Accuracy: 0.737113 Validation Loss: 1.11111 Validation Accuracy: 0.6086\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss: 0.782211 Accuracy: 0.737113 Validation Loss: 1.11473 Validation Accuracy: 0.6048\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss: 0.759321 Accuracy: 0.751289 Validation Loss: 1.10272 Validation Accuracy: 0.6126\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss: 0.781549 Accuracy: 0.759021 Validation Loss: 1.10583 Validation Accuracy: 0.6108\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss: 0.788931 Accuracy: 0.725515 Validation Loss: 1.10829 Validation Accuracy: 0.6146\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss: 0.790435 Accuracy: 0.737113 Validation Loss: 1.12241 Validation Accuracy: 0.6018\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss: 0.782328 Accuracy: 0.752577 Validation Loss: 1.11353 Validation Accuracy: 0.6072\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss: 0.760021 Accuracy: 0.747423 Validation Loss: 1.10926 Validation Accuracy: 0.609\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss: 0.778765 Accuracy: 0.752577 Validation Loss: 1.11249 Validation Accuracy: 0.61\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss: 0.783895 Accuracy: 0.735825 Validation Loss: 1.1044 Validation Accuracy: 0.6108\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss: 0.783586 Accuracy: 0.744845 Validation Loss: 1.11306 Validation Accuracy: 0.6096\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss: 0.788642 Accuracy: 0.742268 Validation Loss: 1.11908 Validation Accuracy: 0.607\n",
      "Epoch 100, CIFAR-10 Batch 4:  Loss: 0.758234 Accuracy: 0.753866 Validation Loss: 1.10499 Validation Accuracy: 0.6106\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss: 0.786565 Accuracy: 0.748711 Validation Loss: 1.11715 Validation Accuracy: 0.6044\n",
      "Epoch 101, CIFAR-10 Batch 1:  Loss: 0.785016 Accuracy: 0.733247 Validation Loss: 1.10364 Validation Accuracy: 0.6114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101, CIFAR-10 Batch 2:  Loss: 0.783833 Accuracy: 0.75 Validation Loss: 1.12762 Validation Accuracy: 0.6052\n",
      "Epoch 101, CIFAR-10 Batch 3:  Loss: 0.785767 Accuracy: 0.740979 Validation Loss: 1.12229 Validation Accuracy: 0.6062\n",
      "Epoch 101, CIFAR-10 Batch 4:  Loss: 0.754727 Accuracy: 0.748711 Validation Loss: 1.10066 Validation Accuracy: 0.6086\n",
      "Epoch 101, CIFAR-10 Batch 5:  Loss: 0.776503 Accuracy: 0.751289 Validation Loss: 1.11313 Validation Accuracy: 0.6044\n",
      "Epoch 102, CIFAR-10 Batch 1:  Loss: 0.776028 Accuracy: 0.73067 Validation Loss: 1.10246 Validation Accuracy: 0.6154\n",
      "Epoch 102, CIFAR-10 Batch 2:  Loss: 0.797939 Accuracy: 0.734536 Validation Loss: 1.12889 Validation Accuracy: 0.6036\n",
      "Epoch 102, CIFAR-10 Batch 3:  Loss: 0.765542 Accuracy: 0.752577 Validation Loss: 1.11087 Validation Accuracy: 0.6086\n",
      "Epoch 102, CIFAR-10 Batch 4:  Loss: 0.766653 Accuracy: 0.743557 Validation Loss: 1.113 Validation Accuracy: 0.605\n",
      "Epoch 102, CIFAR-10 Batch 5:  Loss: 0.775427 Accuracy: 0.756443 Validation Loss: 1.11013 Validation Accuracy: 0.608\n",
      "Epoch 103, CIFAR-10 Batch 1:  Loss: 0.784008 Accuracy: 0.726804 Validation Loss: 1.11871 Validation Accuracy: 0.61\n",
      "Epoch 103, CIFAR-10 Batch 2:  Loss: 0.777325 Accuracy: 0.747423 Validation Loss: 1.11966 Validation Accuracy: 0.6046\n",
      "Epoch 103, CIFAR-10 Batch 3:  Loss: 0.782745 Accuracy: 0.740979 Validation Loss: 1.11139 Validation Accuracy: 0.6072\n",
      "Epoch 103, CIFAR-10 Batch 4:  Loss: 0.756608 Accuracy: 0.744845 Validation Loss: 1.10705 Validation Accuracy: 0.6078\n",
      "Epoch 103, CIFAR-10 Batch 5:  Loss: 0.761191 Accuracy: 0.765464 Validation Loss: 1.09718 Validation Accuracy: 0.6158\n",
      "Epoch 104, CIFAR-10 Batch 1:  Loss: 0.781457 Accuracy: 0.725515 Validation Loss: 1.11415 Validation Accuracy: 0.6096\n",
      "Epoch 104, CIFAR-10 Batch 2:  Loss: 0.764718 Accuracy: 0.744845 Validation Loss: 1.10795 Validation Accuracy: 0.6084\n",
      "Epoch 104, CIFAR-10 Batch 3:  Loss: 0.771845 Accuracy: 0.748711 Validation Loss: 1.10582 Validation Accuracy: 0.612\n",
      "Epoch 104, CIFAR-10 Batch 4:  Loss: 0.751334 Accuracy: 0.743557 Validation Loss: 1.10645 Validation Accuracy: 0.61\n",
      "Epoch 104, CIFAR-10 Batch 5:  Loss: 0.763959 Accuracy: 0.766752 Validation Loss: 1.09973 Validation Accuracy: 0.611\n",
      "Epoch 105, CIFAR-10 Batch 1:  Loss: 0.769509 Accuracy: 0.726804 Validation Loss: 1.10705 Validation Accuracy: 0.615\n",
      "Epoch 105, CIFAR-10 Batch 2:  Loss: 0.762426 Accuracy: 0.751289 Validation Loss: 1.10848 Validation Accuracy: 0.6102\n",
      "Epoch 105, CIFAR-10 Batch 3:  Loss: 0.758724 Accuracy: 0.751289 Validation Loss: 1.09997 Validation Accuracy: 0.6114\n",
      "Epoch 105, CIFAR-10 Batch 4:  Loss: 0.740603 Accuracy: 0.747423 Validation Loss: 1.09851 Validation Accuracy: 0.6116\n",
      "Epoch 105, CIFAR-10 Batch 5:  Loss: 0.751655 Accuracy: 0.768041 Validation Loss: 1.09829 Validation Accuracy: 0.6116\n",
      "Epoch 106, CIFAR-10 Batch 1:  Loss: 0.767858 Accuracy: 0.73067 Validation Loss: 1.11052 Validation Accuracy: 0.6162\n",
      "Epoch 106, CIFAR-10 Batch 2:  Loss: 0.763051 Accuracy: 0.747423 Validation Loss: 1.12074 Validation Accuracy: 0.6068\n",
      "Epoch 106, CIFAR-10 Batch 3:  Loss: 0.769381 Accuracy: 0.757732 Validation Loss: 1.10502 Validation Accuracy: 0.608\n",
      "Epoch 106, CIFAR-10 Batch 4:  Loss: 0.738435 Accuracy: 0.756443 Validation Loss: 1.10462 Validation Accuracy: 0.6112\n",
      "Epoch 106, CIFAR-10 Batch 5:  Loss: 0.759182 Accuracy: 0.766752 Validation Loss: 1.10492 Validation Accuracy: 0.6112\n",
      "Epoch 107, CIFAR-10 Batch 1:  Loss: 0.761249 Accuracy: 0.737113 Validation Loss: 1.10608 Validation Accuracy: 0.616\n",
      "Epoch 107, CIFAR-10 Batch 2:  Loss: 0.765866 Accuracy: 0.743557 Validation Loss: 1.11919 Validation Accuracy: 0.6046\n",
      "Epoch 107, CIFAR-10 Batch 3:  Loss: 0.757672 Accuracy: 0.748711 Validation Loss: 1.09965 Validation Accuracy: 0.6108\n",
      "Epoch 107, CIFAR-10 Batch 4:  Loss: 0.747288 Accuracy: 0.751289 Validation Loss: 1.1103 Validation Accuracy: 0.6118\n",
      "Epoch 107, CIFAR-10 Batch 5:  Loss: 0.756649 Accuracy: 0.760309 Validation Loss: 1.10762 Validation Accuracy: 0.6112\n",
      "Epoch 108, CIFAR-10 Batch 1:  Loss: 0.76524 Accuracy: 0.739691 Validation Loss: 1.11185 Validation Accuracy: 0.6128\n",
      "Epoch 108, CIFAR-10 Batch 2:  Loss: 0.752773 Accuracy: 0.753866 Validation Loss: 1.11579 Validation Accuracy: 0.603\n",
      "Epoch 108, CIFAR-10 Batch 3:  Loss: 0.75256 Accuracy: 0.75 Validation Loss: 1.09939 Validation Accuracy: 0.609\n",
      "Epoch 108, CIFAR-10 Batch 4:  Loss: 0.757273 Accuracy: 0.748711 Validation Loss: 1.12571 Validation Accuracy: 0.6056\n",
      "Epoch 108, CIFAR-10 Batch 5:  Loss: 0.762161 Accuracy: 0.762886 Validation Loss: 1.10961 Validation Accuracy: 0.605\n",
      "Epoch 109, CIFAR-10 Batch 1:  Loss: 0.765013 Accuracy: 0.735825 Validation Loss: 1.11228 Validation Accuracy: 0.6128\n",
      "Epoch 109, CIFAR-10 Batch 2:  Loss: 0.761735 Accuracy: 0.75 Validation Loss: 1.12216 Validation Accuracy: 0.6052\n",
      "Epoch 109, CIFAR-10 Batch 3:  Loss: 0.74682 Accuracy: 0.756443 Validation Loss: 1.09623 Validation Accuracy: 0.6138\n",
      "Epoch 109, CIFAR-10 Batch 4:  Loss: 0.74514 Accuracy: 0.747423 Validation Loss: 1.10713 Validation Accuracy: 0.6104\n",
      "Epoch 109, CIFAR-10 Batch 5:  Loss: 0.738383 Accuracy: 0.773196 Validation Loss: 1.09295 Validation Accuracy: 0.6152\n",
      "Epoch 110, CIFAR-10 Batch 1:  Loss: 0.765928 Accuracy: 0.733247 Validation Loss: 1.11073 Validation Accuracy: 0.6128\n",
      "Epoch 110, CIFAR-10 Batch 2:  Loss: 0.740034 Accuracy: 0.759021 Validation Loss: 1.10574 Validation Accuracy: 0.6084\n",
      "Epoch 110, CIFAR-10 Batch 3:  Loss: 0.750462 Accuracy: 0.761598 Validation Loss: 1.10174 Validation Accuracy: 0.6116\n",
      "Epoch 110, CIFAR-10 Batch 4:  Loss: 0.738254 Accuracy: 0.764175 Validation Loss: 1.10374 Validation Accuracy: 0.6126\n",
      "Epoch 110, CIFAR-10 Batch 5:  Loss: 0.738661 Accuracy: 0.766753 Validation Loss: 1.09772 Validation Accuracy: 0.6146\n",
      "Epoch 111, CIFAR-10 Batch 1:  Loss: 0.751893 Accuracy: 0.743557 Validation Loss: 1.10419 Validation Accuracy: 0.6186\n",
      "Epoch 111, CIFAR-10 Batch 2:  Loss: 0.740563 Accuracy: 0.757732 Validation Loss: 1.10732 Validation Accuracy: 0.6066\n",
      "Epoch 111, CIFAR-10 Batch 3:  Loss: 0.745298 Accuracy: 0.760309 Validation Loss: 1.10237 Validation Accuracy: 0.6138\n",
      "Epoch 111, CIFAR-10 Batch 4:  Loss: 0.722099 Accuracy: 0.748711 Validation Loss: 1.09407 Validation Accuracy: 0.6176\n",
      "Epoch 111, CIFAR-10 Batch 5:  Loss: 0.730944 Accuracy: 0.779639 Validation Loss: 1.09631 Validation Accuracy: 0.6136\n",
      "Epoch 112, CIFAR-10 Batch 1:  Loss: 0.745189 Accuracy: 0.743557 Validation Loss: 1.10547 Validation Accuracy: 0.6182\n",
      "Epoch 112, CIFAR-10 Batch 2:  Loss: 0.741659 Accuracy: 0.75 Validation Loss: 1.11365 Validation Accuracy: 0.6086\n",
      "Epoch 112, CIFAR-10 Batch 3:  Loss: 0.737642 Accuracy: 0.761598 Validation Loss: 1.10215 Validation Accuracy: 0.6136\n",
      "Epoch 112, CIFAR-10 Batch 4:  Loss: 0.72007 Accuracy: 0.755155 Validation Loss: 1.09638 Validation Accuracy: 0.6134\n",
      "Epoch 112, CIFAR-10 Batch 5:  Loss: 0.730008 Accuracy: 0.771907 Validation Loss: 1.09695 Validation Accuracy: 0.6152\n",
      "Epoch 113, CIFAR-10 Batch 1:  Loss: 0.741225 Accuracy: 0.747423 Validation Loss: 1.10309 Validation Accuracy: 0.6174\n",
      "Epoch 113, CIFAR-10 Batch 2:  Loss: 0.733684 Accuracy: 0.765464 Validation Loss: 1.10025 Validation Accuracy: 0.6146\n",
      "Epoch 113, CIFAR-10 Batch 3:  Loss: 0.730286 Accuracy: 0.755155 Validation Loss: 1.10297 Validation Accuracy: 0.607\n",
      "Epoch 113, CIFAR-10 Batch 4:  Loss: 0.731532 Accuracy: 0.751289 Validation Loss: 1.10687 Validation Accuracy: 0.6142\n",
      "Epoch 113, CIFAR-10 Batch 5:  Loss: 0.733561 Accuracy: 0.777062 Validation Loss: 1.0978 Validation Accuracy: 0.6128\n",
      "Epoch 114, CIFAR-10 Batch 1:  Loss: 0.751616 Accuracy: 0.740979 Validation Loss: 1.10787 Validation Accuracy: 0.6144\n",
      "Epoch 114, CIFAR-10 Batch 2:  Loss: 0.725918 Accuracy: 0.765464 Validation Loss: 1.09821 Validation Accuracy: 0.6178\n",
      "Epoch 114, CIFAR-10 Batch 3:  Loss: 0.730393 Accuracy: 0.751289 Validation Loss: 1.1019 Validation Accuracy: 0.6098\n",
      "Epoch 114, CIFAR-10 Batch 4:  Loss: 0.725752 Accuracy: 0.768041 Validation Loss: 1.11349 Validation Accuracy: 0.6126\n",
      "Epoch 114, CIFAR-10 Batch 5:  Loss: 0.725446 Accuracy: 0.775773 Validation Loss: 1.09768 Validation Accuracy: 0.615\n",
      "Epoch 115, CIFAR-10 Batch 1:  Loss: 0.751208 Accuracy: 0.746134 Validation Loss: 1.11115 Validation Accuracy: 0.6154\n",
      "Epoch 115, CIFAR-10 Batch 2:  Loss: 0.730854 Accuracy: 0.761598 Validation Loss: 1.1158 Validation Accuracy: 0.6108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115, CIFAR-10 Batch 3:  Loss: 0.733102 Accuracy: 0.762887 Validation Loss: 1.10797 Validation Accuracy: 0.6068\n",
      "Epoch 115, CIFAR-10 Batch 4:  Loss: 0.7171 Accuracy: 0.756443 Validation Loss: 1.11052 Validation Accuracy: 0.6118\n",
      "Epoch 115, CIFAR-10 Batch 5:  Loss: 0.714286 Accuracy: 0.782216 Validation Loss: 1.09358 Validation Accuracy: 0.6128\n",
      "Epoch 116, CIFAR-10 Batch 1:  Loss: 0.75598 Accuracy: 0.744845 Validation Loss: 1.12178 Validation Accuracy: 0.6112\n",
      "Epoch 116, CIFAR-10 Batch 2:  Loss: 0.7207 Accuracy: 0.761598 Validation Loss: 1.10021 Validation Accuracy: 0.6126\n",
      "Epoch 116, CIFAR-10 Batch 3:  Loss: 0.723388 Accuracy: 0.780928 Validation Loss: 1.09142 Validation Accuracy: 0.6138\n",
      "Epoch 116, CIFAR-10 Batch 4:  Loss: 0.713229 Accuracy: 0.775773 Validation Loss: 1.11534 Validation Accuracy: 0.6046\n",
      "Epoch 116, CIFAR-10 Batch 5:  Loss: 0.720177 Accuracy: 0.771907 Validation Loss: 1.11039 Validation Accuracy: 0.613\n",
      "Epoch 117, CIFAR-10 Batch 1:  Loss: 0.75717 Accuracy: 0.747423 Validation Loss: 1.12982 Validation Accuracy: 0.6074\n",
      "Epoch 117, CIFAR-10 Batch 2:  Loss: 0.727734 Accuracy: 0.748711 Validation Loss: 1.11365 Validation Accuracy: 0.6102\n",
      "Epoch 117, CIFAR-10 Batch 3:  Loss: 0.749562 Accuracy: 0.75 Validation Loss: 1.12692 Validation Accuracy: 0.6008\n",
      "Epoch 117, CIFAR-10 Batch 4:  Loss: 0.72045 Accuracy: 0.77835 Validation Loss: 1.12951 Validation Accuracy: 0.6058\n",
      "Epoch 117, CIFAR-10 Batch 5:  Loss: 0.722492 Accuracy: 0.77835 Validation Loss: 1.11186 Validation Accuracy: 0.6094\n",
      "Epoch 118, CIFAR-10 Batch 1:  Loss: 0.756696 Accuracy: 0.739691 Validation Loss: 1.13216 Validation Accuracy: 0.6034\n",
      "Epoch 118, CIFAR-10 Batch 2:  Loss: 0.742612 Accuracy: 0.748711 Validation Loss: 1.12706 Validation Accuracy: 0.6034\n",
      "Epoch 118, CIFAR-10 Batch 3:  Loss: 0.73782 Accuracy: 0.755155 Validation Loss: 1.12082 Validation Accuracy: 0.6072\n",
      "Epoch 118, CIFAR-10 Batch 4:  Loss: 0.732917 Accuracy: 0.760309 Validation Loss: 1.14237 Validation Accuracy: 0.5952\n",
      "Epoch 118, CIFAR-10 Batch 5:  Loss: 0.752638 Accuracy: 0.739691 Validation Loss: 1.14084 Validation Accuracy: 0.6064\n",
      "Epoch 119, CIFAR-10 Batch 1:  Loss: 0.782982 Accuracy: 0.73067 Validation Loss: 1.14908 Validation Accuracy: 0.5968\n",
      "Epoch 119, CIFAR-10 Batch 2:  Loss: 0.746167 Accuracy: 0.738402 Validation Loss: 1.11917 Validation Accuracy: 0.6036\n",
      "Epoch 119, CIFAR-10 Batch 3:  Loss: 0.761529 Accuracy: 0.743557 Validation Loss: 1.12988 Validation Accuracy: 0.6038\n",
      "Epoch 119, CIFAR-10 Batch 4:  Loss: 0.716426 Accuracy: 0.771907 Validation Loss: 1.11546 Validation Accuracy: 0.606\n",
      "Epoch 119, CIFAR-10 Batch 5:  Loss: 0.707756 Accuracy: 0.768041 Validation Loss: 1.09869 Validation Accuracy: 0.6168\n",
      "Epoch 120, CIFAR-10 Batch 1:  Loss: 0.736193 Accuracy: 0.746134 Validation Loss: 1.10576 Validation Accuracy: 0.6184\n",
      "Epoch 120, CIFAR-10 Batch 2:  Loss: 0.730045 Accuracy: 0.752577 Validation Loss: 1.10162 Validation Accuracy: 0.611\n",
      "Epoch 120, CIFAR-10 Batch 3:  Loss: 0.712523 Accuracy: 0.770618 Validation Loss: 1.10738 Validation Accuracy: 0.613\n",
      "Epoch 120, CIFAR-10 Batch 4:  Loss: 0.720135 Accuracy: 0.761598 Validation Loss: 1.10766 Validation Accuracy: 0.6114\n",
      "Epoch 120, CIFAR-10 Batch 5:  Loss: 0.70456 Accuracy: 0.784794 Validation Loss: 1.0986 Validation Accuracy: 0.6158\n",
      "Epoch 121, CIFAR-10 Batch 1:  Loss: 0.726931 Accuracy: 0.755155 Validation Loss: 1.10903 Validation Accuracy: 0.6156\n",
      "Epoch 121, CIFAR-10 Batch 2:  Loss: 0.726581 Accuracy: 0.759021 Validation Loss: 1.09875 Validation Accuracy: 0.615\n",
      "Epoch 121, CIFAR-10 Batch 3:  Loss: 0.720862 Accuracy: 0.764175 Validation Loss: 1.12366 Validation Accuracy: 0.6008\n",
      "Epoch 121, CIFAR-10 Batch 4:  Loss: 0.72902 Accuracy: 0.760309 Validation Loss: 1.12217 Validation Accuracy: 0.607\n",
      "Epoch 121, CIFAR-10 Batch 5:  Loss: 0.712168 Accuracy: 0.777062 Validation Loss: 1.10453 Validation Accuracy: 0.6126\n",
      "Epoch 122, CIFAR-10 Batch 1:  Loss: 0.72893 Accuracy: 0.752577 Validation Loss: 1.1024 Validation Accuracy: 0.6136\n",
      "Epoch 122, CIFAR-10 Batch 2:  Loss: 0.710598 Accuracy: 0.762887 Validation Loss: 1.10022 Validation Accuracy: 0.614\n",
      "Epoch 122, CIFAR-10 Batch 3:  Loss: 0.719447 Accuracy: 0.77835 Validation Loss: 1.11681 Validation Accuracy: 0.6054\n",
      "Epoch 122, CIFAR-10 Batch 4:  Loss: 0.717665 Accuracy: 0.770619 Validation Loss: 1.1237 Validation Accuracy: 0.6032\n",
      "Epoch 122, CIFAR-10 Batch 5:  Loss: 0.708741 Accuracy: 0.786082 Validation Loss: 1.10804 Validation Accuracy: 0.6128\n",
      "Epoch 123, CIFAR-10 Batch 1:  Loss: 0.723078 Accuracy: 0.753866 Validation Loss: 1.1108 Validation Accuracy: 0.6108\n",
      "Epoch 123, CIFAR-10 Batch 2:  Loss: 0.703468 Accuracy: 0.764175 Validation Loss: 1.10104 Validation Accuracy: 0.6112\n",
      "Epoch 123, CIFAR-10 Batch 3:  Loss: 0.710084 Accuracy: 0.77835 Validation Loss: 1.10999 Validation Accuracy: 0.6098\n",
      "Epoch 123, CIFAR-10 Batch 4:  Loss: 0.706445 Accuracy: 0.773196 Validation Loss: 1.11926 Validation Accuracy: 0.6056\n",
      "Epoch 123, CIFAR-10 Batch 5:  Loss: 0.701599 Accuracy: 0.783505 Validation Loss: 1.11149 Validation Accuracy: 0.6112\n",
      "Epoch 124, CIFAR-10 Batch 1:  Loss: 0.736933 Accuracy: 0.75 Validation Loss: 1.12275 Validation Accuracy: 0.6094\n",
      "Epoch 124, CIFAR-10 Batch 2:  Loss: 0.730901 Accuracy: 0.753866 Validation Loss: 1.1156 Validation Accuracy: 0.611\n",
      "Epoch 124, CIFAR-10 Batch 3:  Loss: 0.746464 Accuracy: 0.75 Validation Loss: 1.14218 Validation Accuracy: 0.5978\n",
      "Epoch 124, CIFAR-10 Batch 4:  Loss: 0.718424 Accuracy: 0.77835 Validation Loss: 1.12904 Validation Accuracy: 0.5992\n",
      "Epoch 124, CIFAR-10 Batch 5:  Loss: 0.717329 Accuracy: 0.770618 Validation Loss: 1.12919 Validation Accuracy: 0.6032\n",
      "Epoch 125, CIFAR-10 Batch 1:  Loss: 0.738086 Accuracy: 0.75 Validation Loss: 1.12363 Validation Accuracy: 0.6108\n",
      "Epoch 125, CIFAR-10 Batch 2:  Loss: 0.715136 Accuracy: 0.761598 Validation Loss: 1.11682 Validation Accuracy: 0.6096\n",
      "Epoch 125, CIFAR-10 Batch 3:  Loss: 0.70603 Accuracy: 0.765464 Validation Loss: 1.11185 Validation Accuracy: 0.6076\n",
      "Epoch 125, CIFAR-10 Batch 4:  Loss: 0.738487 Accuracy: 0.759021 Validation Loss: 1.16329 Validation Accuracy: 0.5886\n",
      "Epoch 125, CIFAR-10 Batch 5:  Loss: 0.716312 Accuracy: 0.774484 Validation Loss: 1.12629 Validation Accuracy: 0.6026\n",
      "Epoch 126, CIFAR-10 Batch 1:  Loss: 0.735666 Accuracy: 0.755155 Validation Loss: 1.11384 Validation Accuracy: 0.6092\n",
      "Epoch 126, CIFAR-10 Batch 2:  Loss: 0.717969 Accuracy: 0.757732 Validation Loss: 1.11341 Validation Accuracy: 0.6126\n",
      "Epoch 126, CIFAR-10 Batch 3:  Loss: 0.71682 Accuracy: 0.761598 Validation Loss: 1.12277 Validation Accuracy: 0.6032\n",
      "Epoch 126, CIFAR-10 Batch 4:  Loss: 0.767522 Accuracy: 0.753866 Validation Loss: 1.19459 Validation Accuracy: 0.5814\n",
      "Epoch 126, CIFAR-10 Batch 5:  Loss: 0.712096 Accuracy: 0.770618 Validation Loss: 1.11433 Validation Accuracy: 0.6096\n",
      "Epoch 127, CIFAR-10 Batch 1:  Loss: 0.760749 Accuracy: 0.743557 Validation Loss: 1.14259 Validation Accuracy: 0.5984\n",
      "Epoch 127, CIFAR-10 Batch 2:  Loss: 0.725374 Accuracy: 0.748711 Validation Loss: 1.11889 Validation Accuracy: 0.607\n",
      "Epoch 127, CIFAR-10 Batch 3:  Loss: 0.726749 Accuracy: 0.761598 Validation Loss: 1.12292 Validation Accuracy: 0.6046\n",
      "Epoch 127, CIFAR-10 Batch 4:  Loss: 0.731478 Accuracy: 0.765464 Validation Loss: 1.14507 Validation Accuracy: 0.5938\n",
      "Epoch 127, CIFAR-10 Batch 5:  Loss: 0.781796 Accuracy: 0.735825 Validation Loss: 1.18193 Validation Accuracy: 0.5926\n",
      "Epoch 128, CIFAR-10 Batch 1:  Loss: 0.812595 Accuracy: 0.717783 Validation Loss: 1.17007 Validation Accuracy: 0.5966\n",
      "Epoch 128, CIFAR-10 Batch 2:  Loss: 0.778901 Accuracy: 0.729381 Validation Loss: 1.15857 Validation Accuracy: 0.5926\n",
      "Epoch 128, CIFAR-10 Batch 3:  Loss: 0.754218 Accuracy: 0.765464 Validation Loss: 1.14556 Validation Accuracy: 0.597\n",
      "Epoch 128, CIFAR-10 Batch 4:  Loss: 0.727445 Accuracy: 0.759021 Validation Loss: 1.11314 Validation Accuracy: 0.612\n",
      "Epoch 128, CIFAR-10 Batch 5:  Loss: 0.715532 Accuracy: 0.768041 Validation Loss: 1.12351 Validation Accuracy: 0.6098\n",
      "Epoch 129, CIFAR-10 Batch 1:  Loss: 0.738346 Accuracy: 0.746134 Validation Loss: 1.11564 Validation Accuracy: 0.6136\n",
      "Epoch 129, CIFAR-10 Batch 2:  Loss: 0.707263 Accuracy: 0.755154 Validation Loss: 1.11891 Validation Accuracy: 0.6074\n",
      "Epoch 129, CIFAR-10 Batch 3:  Loss: 0.697332 Accuracy: 0.77835 Validation Loss: 1.09778 Validation Accuracy: 0.6148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129, CIFAR-10 Batch 4:  Loss: 0.700252 Accuracy: 0.76933 Validation Loss: 1.10409 Validation Accuracy: 0.6148\n",
      "Epoch 129, CIFAR-10 Batch 5:  Loss: 0.700805 Accuracy: 0.766753 Validation Loss: 1.11104 Validation Accuracy: 0.6172\n",
      "Epoch 130, CIFAR-10 Batch 1:  Loss: 0.765052 Accuracy: 0.738402 Validation Loss: 1.14504 Validation Accuracy: 0.607\n",
      "Epoch 130, CIFAR-10 Batch 2:  Loss: 0.727791 Accuracy: 0.755155 Validation Loss: 1.14062 Validation Accuracy: 0.6002\n",
      "Epoch 130, CIFAR-10 Batch 3:  Loss: 0.712457 Accuracy: 0.780928 Validation Loss: 1.1169 Validation Accuracy: 0.605\n",
      "Epoch 130, CIFAR-10 Batch 4:  Loss: 0.69819 Accuracy: 0.77835 Validation Loss: 1.10022 Validation Accuracy: 0.61\n",
      "Epoch 130, CIFAR-10 Batch 5:  Loss: 0.715174 Accuracy: 0.755155 Validation Loss: 1.14795 Validation Accuracy: 0.5988\n",
      "Epoch 131, CIFAR-10 Batch 1:  Loss: 0.723369 Accuracy: 0.752577 Validation Loss: 1.10683 Validation Accuracy: 0.6126\n",
      "Epoch 131, CIFAR-10 Batch 2:  Loss: 0.765458 Accuracy: 0.726804 Validation Loss: 1.18577 Validation Accuracy: 0.5852\n",
      "Epoch 131, CIFAR-10 Batch 3:  Loss: 0.77028 Accuracy: 0.726804 Validation Loss: 1.16858 Validation Accuracy: 0.5856\n",
      "Epoch 131, CIFAR-10 Batch 4:  Loss: 0.754826 Accuracy: 0.744845 Validation Loss: 1.14593 Validation Accuracy: 0.5972\n",
      "Epoch 131, CIFAR-10 Batch 5:  Loss: 0.714785 Accuracy: 0.779639 Validation Loss: 1.11471 Validation Accuracy: 0.6056\n",
      "Epoch 132, CIFAR-10 Batch 1:  Loss: 0.717265 Accuracy: 0.75 Validation Loss: 1.10151 Validation Accuracy: 0.6122\n",
      "Epoch 132, CIFAR-10 Batch 2:  Loss: 0.68387 Accuracy: 0.779639 Validation Loss: 1.10793 Validation Accuracy: 0.6128\n",
      "Epoch 132, CIFAR-10 Batch 3:  Loss: 0.710427 Accuracy: 0.766752 Validation Loss: 1.12726 Validation Accuracy: 0.6046\n",
      "Epoch 132, CIFAR-10 Batch 4:  Loss: 0.713175 Accuracy: 0.764175 Validation Loss: 1.12228 Validation Accuracy: 0.6094\n",
      "Epoch 132, CIFAR-10 Batch 5:  Loss: 0.687265 Accuracy: 0.782216 Validation Loss: 1.11089 Validation Accuracy: 0.614\n",
      "Epoch 133, CIFAR-10 Batch 1:  Loss: 0.703594 Accuracy: 0.757732 Validation Loss: 1.1108 Validation Accuracy: 0.6142\n",
      "Epoch 133, CIFAR-10 Batch 2:  Loss: 0.696427 Accuracy: 0.768041 Validation Loss: 1.12598 Validation Accuracy: 0.6072\n",
      "Epoch 133, CIFAR-10 Batch 3:  Loss: 0.718162 Accuracy: 0.756443 Validation Loss: 1.13743 Validation Accuracy: 0.5986\n",
      "Epoch 133, CIFAR-10 Batch 4:  Loss: 0.696496 Accuracy: 0.76933 Validation Loss: 1.10501 Validation Accuracy: 0.6106\n",
      "Epoch 133, CIFAR-10 Batch 5:  Loss: 0.688053 Accuracy: 0.777062 Validation Loss: 1.1198 Validation Accuracy: 0.6108\n",
      "Epoch 134, CIFAR-10 Batch 1:  Loss: 0.707415 Accuracy: 0.762887 Validation Loss: 1.10914 Validation Accuracy: 0.6184\n",
      "Epoch 134, CIFAR-10 Batch 2:  Loss: 0.684269 Accuracy: 0.761598 Validation Loss: 1.11733 Validation Accuracy: 0.6104\n",
      "Epoch 134, CIFAR-10 Batch 3:  Loss: 0.725103 Accuracy: 0.748711 Validation Loss: 1.14524 Validation Accuracy: 0.598\n",
      "Epoch 134, CIFAR-10 Batch 4:  Loss: 0.723048 Accuracy: 0.75 Validation Loss: 1.13189 Validation Accuracy: 0.6026\n",
      "Epoch 134, CIFAR-10 Batch 5:  Loss: 0.701349 Accuracy: 0.774484 Validation Loss: 1.12193 Validation Accuracy: 0.6076\n",
      "Epoch 135, CIFAR-10 Batch 1:  Loss: 0.718328 Accuracy: 0.746134 Validation Loss: 1.11222 Validation Accuracy: 0.614\n",
      "Epoch 135, CIFAR-10 Batch 2:  Loss: 0.668931 Accuracy: 0.777062 Validation Loss: 1.10152 Validation Accuracy: 0.6154\n",
      "Epoch 135, CIFAR-10 Batch 3:  Loss: 0.690981 Accuracy: 0.782216 Validation Loss: 1.11603 Validation Accuracy: 0.608\n",
      "Epoch 135, CIFAR-10 Batch 4:  Loss: 0.709904 Accuracy: 0.762887 Validation Loss: 1.12712 Validation Accuracy: 0.603\n",
      "Epoch 135, CIFAR-10 Batch 5:  Loss: 0.676332 Accuracy: 0.792526 Validation Loss: 1.10261 Validation Accuracy: 0.614\n",
      "Epoch 136, CIFAR-10 Batch 1:  Loss: 0.698267 Accuracy: 0.766752 Validation Loss: 1.10335 Validation Accuracy: 0.618\n",
      "Epoch 136, CIFAR-10 Batch 2:  Loss: 0.677946 Accuracy: 0.774485 Validation Loss: 1.11866 Validation Accuracy: 0.6108\n",
      "Epoch 136, CIFAR-10 Batch 3:  Loss: 0.711518 Accuracy: 0.759021 Validation Loss: 1.1342 Validation Accuracy: 0.6016\n",
      "Epoch 136, CIFAR-10 Batch 4:  Loss: 0.702236 Accuracy: 0.764175 Validation Loss: 1.11656 Validation Accuracy: 0.608\n",
      "Epoch 136, CIFAR-10 Batch 5:  Loss: 0.683262 Accuracy: 0.793814 Validation Loss: 1.11003 Validation Accuracy: 0.6094\n",
      "Epoch 137, CIFAR-10 Batch 1:  Loss: 0.687527 Accuracy: 0.766752 Validation Loss: 1.10146 Validation Accuracy: 0.617\n",
      "Epoch 137, CIFAR-10 Batch 2:  Loss: 0.671544 Accuracy: 0.784794 Validation Loss: 1.11073 Validation Accuracy: 0.609\n",
      "Epoch 137, CIFAR-10 Batch 3:  Loss: 0.701236 Accuracy: 0.76933 Validation Loss: 1.12633 Validation Accuracy: 0.6042\n",
      "Epoch 137, CIFAR-10 Batch 4:  Loss: 0.699651 Accuracy: 0.760309 Validation Loss: 1.12475 Validation Accuracy: 0.609\n",
      "Epoch 137, CIFAR-10 Batch 5:  Loss: 0.675582 Accuracy: 0.791237 Validation Loss: 1.10268 Validation Accuracy: 0.6126\n",
      "Epoch 138, CIFAR-10 Batch 1:  Loss: 0.691706 Accuracy: 0.762887 Validation Loss: 1.10307 Validation Accuracy: 0.619\n",
      "Epoch 138, CIFAR-10 Batch 2:  Loss: 0.66945 Accuracy: 0.783505 Validation Loss: 1.11782 Validation Accuracy: 0.611\n",
      "Epoch 138, CIFAR-10 Batch 3:  Loss: 0.702367 Accuracy: 0.766752 Validation Loss: 1.13458 Validation Accuracy: 0.5972\n",
      "Epoch 138, CIFAR-10 Batch 4:  Loss: 0.691612 Accuracy: 0.774485 Validation Loss: 1.11718 Validation Accuracy: 0.6102\n",
      "Epoch 138, CIFAR-10 Batch 5:  Loss: 0.663007 Accuracy: 0.786082 Validation Loss: 1.09942 Validation Accuracy: 0.619\n",
      "Epoch 139, CIFAR-10 Batch 1:  Loss: 0.677731 Accuracy: 0.770618 Validation Loss: 1.10067 Validation Accuracy: 0.6202\n",
      "Epoch 139, CIFAR-10 Batch 2:  Loss: 0.662475 Accuracy: 0.780928 Validation Loss: 1.1152 Validation Accuracy: 0.6116\n",
      "Epoch 139, CIFAR-10 Batch 3:  Loss: 0.677545 Accuracy: 0.784794 Validation Loss: 1.11637 Validation Accuracy: 0.607\n",
      "Epoch 139, CIFAR-10 Batch 4:  Loss: 0.690712 Accuracy: 0.768041 Validation Loss: 1.11583 Validation Accuracy: 0.6114\n",
      "Epoch 139, CIFAR-10 Batch 5:  Loss: 0.663381 Accuracy: 0.784794 Validation Loss: 1.10558 Validation Accuracy: 0.6182\n",
      "Epoch 140, CIFAR-10 Batch 1:  Loss: 0.680094 Accuracy: 0.764175 Validation Loss: 1.10417 Validation Accuracy: 0.6188\n",
      "Epoch 140, CIFAR-10 Batch 2:  Loss: 0.663663 Accuracy: 0.784794 Validation Loss: 1.11249 Validation Accuracy: 0.612\n",
      "Epoch 140, CIFAR-10 Batch 3:  Loss: 0.686314 Accuracy: 0.76933 Validation Loss: 1.12851 Validation Accuracy: 0.6038\n",
      "Epoch 140, CIFAR-10 Batch 4:  Loss: 0.690203 Accuracy: 0.768041 Validation Loss: 1.11192 Validation Accuracy: 0.6122\n",
      "Epoch 140, CIFAR-10 Batch 5:  Loss: 0.672902 Accuracy: 0.78866 Validation Loss: 1.11907 Validation Accuracy: 0.611\n",
      "Epoch 141, CIFAR-10 Batch 1:  Loss: 0.678779 Accuracy: 0.770618 Validation Loss: 1.09571 Validation Accuracy: 0.6174\n",
      "Epoch 141, CIFAR-10 Batch 2:  Loss: 0.680776 Accuracy: 0.775773 Validation Loss: 1.14022 Validation Accuracy: 0.6046\n",
      "Epoch 141, CIFAR-10 Batch 3:  Loss: 0.677388 Accuracy: 0.779639 Validation Loss: 1.12341 Validation Accuracy: 0.6042\n",
      "Epoch 141, CIFAR-10 Batch 4:  Loss: 0.673469 Accuracy: 0.77835 Validation Loss: 1.10635 Validation Accuracy: 0.6164\n",
      "Epoch 141, CIFAR-10 Batch 5:  Loss: 0.659299 Accuracy: 0.783505 Validation Loss: 1.1102 Validation Accuracy: 0.6174\n",
      "Epoch 142, CIFAR-10 Batch 1:  Loss: 0.672571 Accuracy: 0.76933 Validation Loss: 1.09882 Validation Accuracy: 0.616\n",
      "Epoch 142, CIFAR-10 Batch 2:  Loss: 0.673707 Accuracy: 0.782216 Validation Loss: 1.13492 Validation Accuracy: 0.6056\n",
      "Epoch 142, CIFAR-10 Batch 3:  Loss: 0.67361 Accuracy: 0.774484 Validation Loss: 1.12624 Validation Accuracy: 0.6032\n",
      "Epoch 142, CIFAR-10 Batch 4:  Loss: 0.669727 Accuracy: 0.782216 Validation Loss: 1.10342 Validation Accuracy: 0.6114\n",
      "Epoch 142, CIFAR-10 Batch 5:  Loss: 0.658276 Accuracy: 0.784794 Validation Loss: 1.1099 Validation Accuracy: 0.62\n",
      "Epoch 143, CIFAR-10 Batch 1:  Loss: 0.673403 Accuracy: 0.774484 Validation Loss: 1.10214 Validation Accuracy: 0.6178\n",
      "Epoch 143, CIFAR-10 Batch 2:  Loss: 0.666537 Accuracy: 0.77835 Validation Loss: 1.12803 Validation Accuracy: 0.6076\n",
      "Epoch 143, CIFAR-10 Batch 3:  Loss: 0.673057 Accuracy: 0.774484 Validation Loss: 1.12327 Validation Accuracy: 0.6054\n",
      "Epoch 143, CIFAR-10 Batch 4:  Loss: 0.665752 Accuracy: 0.784794 Validation Loss: 1.10323 Validation Accuracy: 0.6144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143, CIFAR-10 Batch 5:  Loss: 0.656206 Accuracy: 0.779639 Validation Loss: 1.10718 Validation Accuracy: 0.6154\n",
      "Epoch 144, CIFAR-10 Batch 1:  Loss: 0.66978 Accuracy: 0.76933 Validation Loss: 1.10015 Validation Accuracy: 0.6178\n",
      "Epoch 144, CIFAR-10 Batch 2:  Loss: 0.644062 Accuracy: 0.787371 Validation Loss: 1.11126 Validation Accuracy: 0.6146\n",
      "Epoch 144, CIFAR-10 Batch 3:  Loss: 0.667419 Accuracy: 0.777062 Validation Loss: 1.12411 Validation Accuracy: 0.606\n",
      "Epoch 144, CIFAR-10 Batch 4:  Loss: 0.666285 Accuracy: 0.784794 Validation Loss: 1.10741 Validation Accuracy: 0.6112\n",
      "Epoch 144, CIFAR-10 Batch 5:  Loss: 0.653994 Accuracy: 0.786082 Validation Loss: 1.11426 Validation Accuracy: 0.6124\n",
      "Epoch 145, CIFAR-10 Batch 1:  Loss: 0.671654 Accuracy: 0.765464 Validation Loss: 1.10699 Validation Accuracy: 0.6162\n",
      "Epoch 145, CIFAR-10 Batch 2:  Loss: 0.642551 Accuracy: 0.793814 Validation Loss: 1.10691 Validation Accuracy: 0.6156\n",
      "Epoch 145, CIFAR-10 Batch 3:  Loss: 0.66422 Accuracy: 0.783505 Validation Loss: 1.12424 Validation Accuracy: 0.607\n",
      "Epoch 145, CIFAR-10 Batch 4:  Loss: 0.667156 Accuracy: 0.786082 Validation Loss: 1.1106 Validation Accuracy: 0.614\n",
      "Epoch 145, CIFAR-10 Batch 5:  Loss: 0.649093 Accuracy: 0.791237 Validation Loss: 1.11049 Validation Accuracy: 0.6144\n",
      "Epoch 146, CIFAR-10 Batch 1:  Loss: 0.667868 Accuracy: 0.765464 Validation Loss: 1.10298 Validation Accuracy: 0.6184\n",
      "Epoch 146, CIFAR-10 Batch 2:  Loss: 0.654435 Accuracy: 0.786082 Validation Loss: 1.11881 Validation Accuracy: 0.6122\n",
      "Epoch 146, CIFAR-10 Batch 3:  Loss: 0.63605 Accuracy: 0.804124 Validation Loss: 1.10002 Validation Accuracy: 0.6106\n",
      "Epoch 146, CIFAR-10 Batch 4:  Loss: 0.64842 Accuracy: 0.783505 Validation Loss: 1.09873 Validation Accuracy: 0.6158\n",
      "Epoch 146, CIFAR-10 Batch 5:  Loss: 0.646082 Accuracy: 0.789948 Validation Loss: 1.11083 Validation Accuracy: 0.6146\n",
      "Epoch 147, CIFAR-10 Batch 1:  Loss: 0.650358 Accuracy: 0.779639 Validation Loss: 1.09595 Validation Accuracy: 0.6198\n",
      "Epoch 147, CIFAR-10 Batch 2:  Loss: 0.636413 Accuracy: 0.792526 Validation Loss: 1.10931 Validation Accuracy: 0.6134\n",
      "Epoch 147, CIFAR-10 Batch 3:  Loss: 0.645709 Accuracy: 0.791237 Validation Loss: 1.11469 Validation Accuracy: 0.6098\n",
      "Epoch 147, CIFAR-10 Batch 4:  Loss: 0.651169 Accuracy: 0.796392 Validation Loss: 1.10331 Validation Accuracy: 0.6138\n",
      "Epoch 147, CIFAR-10 Batch 5:  Loss: 0.635713 Accuracy: 0.789948 Validation Loss: 1.10898 Validation Accuracy: 0.6178\n",
      "Epoch 148, CIFAR-10 Batch 1:  Loss: 0.667336 Accuracy: 0.770618 Validation Loss: 1.10882 Validation Accuracy: 0.615\n",
      "Epoch 148, CIFAR-10 Batch 2:  Loss: 0.628508 Accuracy: 0.791237 Validation Loss: 1.09197 Validation Accuracy: 0.6174\n",
      "Epoch 148, CIFAR-10 Batch 3:  Loss: 0.632019 Accuracy: 0.798969 Validation Loss: 1.10143 Validation Accuracy: 0.614\n",
      "Epoch 148, CIFAR-10 Batch 4:  Loss: 0.652105 Accuracy: 0.77835 Validation Loss: 1.10009 Validation Accuracy: 0.6162\n",
      "Epoch 148, CIFAR-10 Batch 5:  Loss: 0.633458 Accuracy: 0.79768 Validation Loss: 1.10702 Validation Accuracy: 0.6164\n",
      "Epoch 149, CIFAR-10 Batch 1:  Loss: 0.65569 Accuracy: 0.773196 Validation Loss: 1.1025 Validation Accuracy: 0.6162\n",
      "Epoch 149, CIFAR-10 Batch 2:  Loss: 0.62774 Accuracy: 0.795103 Validation Loss: 1.09542 Validation Accuracy: 0.6218\n",
      "Epoch 149, CIFAR-10 Batch 3:  Loss: 0.634156 Accuracy: 0.801546 Validation Loss: 1.10645 Validation Accuracy: 0.6148\n",
      "Epoch 149, CIFAR-10 Batch 4:  Loss: 0.649584 Accuracy: 0.78866 Validation Loss: 1.10202 Validation Accuracy: 0.6192\n",
      "Epoch 149, CIFAR-10 Batch 5:  Loss: 0.623149 Accuracy: 0.795103 Validation Loss: 1.09925 Validation Accuracy: 0.6196\n",
      "Epoch 150, CIFAR-10 Batch 1:  Loss: 0.652347 Accuracy: 0.777062 Validation Loss: 1.10525 Validation Accuracy: 0.6186\n",
      "Epoch 150, CIFAR-10 Batch 2:  Loss: 0.622842 Accuracy: 0.792526 Validation Loss: 1.09721 Validation Accuracy: 0.6204\n",
      "Epoch 150, CIFAR-10 Batch 3:  Loss: 0.624806 Accuracy: 0.804124 Validation Loss: 1.10244 Validation Accuracy: 0.6154\n",
      "Epoch 150, CIFAR-10 Batch 4:  Loss: 0.643317 Accuracy: 0.792526 Validation Loss: 1.10362 Validation Accuracy: 0.6184\n",
      "Epoch 150, CIFAR-10 Batch 5:  Loss: 0.620842 Accuracy: 0.802835 Validation Loss: 1.09912 Validation Accuracy: 0.6198\n",
      "Epoch 151, CIFAR-10 Batch 1:  Loss: 0.651693 Accuracy: 0.774485 Validation Loss: 1.10571 Validation Accuracy: 0.6182\n",
      "Epoch 151, CIFAR-10 Batch 2:  Loss: 0.620121 Accuracy: 0.795103 Validation Loss: 1.10267 Validation Accuracy: 0.615\n",
      "Epoch 151, CIFAR-10 Batch 3:  Loss: 0.631866 Accuracy: 0.804124 Validation Loss: 1.11131 Validation Accuracy: 0.6142\n",
      "Epoch 151, CIFAR-10 Batch 4:  Loss: 0.64135 Accuracy: 0.787371 Validation Loss: 1.10852 Validation Accuracy: 0.6154\n",
      "Epoch 151, CIFAR-10 Batch 5:  Loss: 0.625807 Accuracy: 0.782216 Validation Loss: 1.10625 Validation Accuracy: 0.6194\n",
      "Epoch 152, CIFAR-10 Batch 1:  Loss: 0.66185 Accuracy: 0.770618 Validation Loss: 1.12156 Validation Accuracy: 0.616\n",
      "Epoch 152, CIFAR-10 Batch 2:  Loss: 0.614344 Accuracy: 0.789948 Validation Loss: 1.09494 Validation Accuracy: 0.6212\n",
      "Epoch 152, CIFAR-10 Batch 3:  Loss: 0.632043 Accuracy: 0.795103 Validation Loss: 1.11399 Validation Accuracy: 0.6162\n",
      "Epoch 152, CIFAR-10 Batch 4:  Loss: 0.655457 Accuracy: 0.777062 Validation Loss: 1.12287 Validation Accuracy: 0.6122\n",
      "Epoch 152, CIFAR-10 Batch 5:  Loss: 0.620204 Accuracy: 0.802835 Validation Loss: 1.1014 Validation Accuracy: 0.617\n",
      "Epoch 153, CIFAR-10 Batch 1:  Loss: 0.643752 Accuracy: 0.774484 Validation Loss: 1.10374 Validation Accuracy: 0.6184\n",
      "Epoch 153, CIFAR-10 Batch 2:  Loss: 0.621683 Accuracy: 0.793814 Validation Loss: 1.10863 Validation Accuracy: 0.6186\n",
      "Epoch 153, CIFAR-10 Batch 3:  Loss: 0.620857 Accuracy: 0.813144 Validation Loss: 1.10418 Validation Accuracy: 0.6096\n",
      "Epoch 153, CIFAR-10 Batch 4:  Loss: 0.649049 Accuracy: 0.779639 Validation Loss: 1.11652 Validation Accuracy: 0.616\n",
      "Epoch 153, CIFAR-10 Batch 5:  Loss: 0.617883 Accuracy: 0.798969 Validation Loss: 1.10512 Validation Accuracy: 0.6188\n",
      "Epoch 154, CIFAR-10 Batch 1:  Loss: 0.648289 Accuracy: 0.782216 Validation Loss: 1.11154 Validation Accuracy: 0.6172\n",
      "Epoch 154, CIFAR-10 Batch 2:  Loss: 0.613726 Accuracy: 0.802835 Validation Loss: 1.0926 Validation Accuracy: 0.6194\n",
      "Epoch 154, CIFAR-10 Batch 3:  Loss: 0.631005 Accuracy: 0.79768 Validation Loss: 1.11704 Validation Accuracy: 0.6112\n",
      "Epoch 154, CIFAR-10 Batch 4:  Loss: 0.647281 Accuracy: 0.784794 Validation Loss: 1.11967 Validation Accuracy: 0.6124\n",
      "Epoch 154, CIFAR-10 Batch 5:  Loss: 0.619106 Accuracy: 0.789948 Validation Loss: 1.10908 Validation Accuracy: 0.6182\n",
      "Epoch 155, CIFAR-10 Batch 1:  Loss: 0.652693 Accuracy: 0.774484 Validation Loss: 1.11236 Validation Accuracy: 0.6152\n",
      "Epoch 155, CIFAR-10 Batch 2:  Loss: 0.658094 Accuracy: 0.777062 Validation Loss: 1.15367 Validation Accuracy: 0.602\n",
      "Epoch 155, CIFAR-10 Batch 3:  Loss: 0.628911 Accuracy: 0.80799 Validation Loss: 1.11419 Validation Accuracy: 0.6096\n",
      "Epoch 155, CIFAR-10 Batch 4:  Loss: 0.644575 Accuracy: 0.771907 Validation Loss: 1.11553 Validation Accuracy: 0.6138\n",
      "Epoch 155, CIFAR-10 Batch 5:  Loss: 0.634754 Accuracy: 0.787371 Validation Loss: 1.11777 Validation Accuracy: 0.6156\n",
      "Epoch 156, CIFAR-10 Batch 1:  Loss: 0.645413 Accuracy: 0.773196 Validation Loss: 1.1125 Validation Accuracy: 0.6164\n",
      "Epoch 156, CIFAR-10 Batch 2:  Loss: 0.619356 Accuracy: 0.798969 Validation Loss: 1.11228 Validation Accuracy: 0.6186\n",
      "Epoch 156, CIFAR-10 Batch 3:  Loss: 0.619438 Accuracy: 0.809278 Validation Loss: 1.10607 Validation Accuracy: 0.6146\n",
      "Epoch 156, CIFAR-10 Batch 4:  Loss: 0.626065 Accuracy: 0.78866 Validation Loss: 1.10042 Validation Accuracy: 0.621\n",
      "Epoch 156, CIFAR-10 Batch 5:  Loss: 0.614218 Accuracy: 0.791237 Validation Loss: 1.1078 Validation Accuracy: 0.619\n",
      "Epoch 157, CIFAR-10 Batch 1:  Loss: 0.636228 Accuracy: 0.775773 Validation Loss: 1.10672 Validation Accuracy: 0.6204\n",
      "Epoch 157, CIFAR-10 Batch 2:  Loss: 0.617824 Accuracy: 0.798969 Validation Loss: 1.10905 Validation Accuracy: 0.6156\n",
      "Epoch 157, CIFAR-10 Batch 3:  Loss: 0.608625 Accuracy: 0.805412 Validation Loss: 1.10002 Validation Accuracy: 0.6192\n",
      "Epoch 157, CIFAR-10 Batch 4:  Loss: 0.629232 Accuracy: 0.779639 Validation Loss: 1.10383 Validation Accuracy: 0.619\n",
      "Epoch 157, CIFAR-10 Batch 5:  Loss: 0.60665 Accuracy: 0.78866 Validation Loss: 1.10465 Validation Accuracy: 0.6174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158, CIFAR-10 Batch 1:  Loss: 0.630247 Accuracy: 0.775773 Validation Loss: 1.10249 Validation Accuracy: 0.621\n",
      "Epoch 158, CIFAR-10 Batch 2:  Loss: 0.61585 Accuracy: 0.802835 Validation Loss: 1.11722 Validation Accuracy: 0.6182\n",
      "Epoch 158, CIFAR-10 Batch 3:  Loss: 0.610565 Accuracy: 0.80799 Validation Loss: 1.10488 Validation Accuracy: 0.6124\n",
      "Epoch 158, CIFAR-10 Batch 4:  Loss: 0.624578 Accuracy: 0.78866 Validation Loss: 1.10584 Validation Accuracy: 0.6188\n",
      "Epoch 158, CIFAR-10 Batch 5:  Loss: 0.604445 Accuracy: 0.791237 Validation Loss: 1.10365 Validation Accuracy: 0.619\n",
      "Epoch 159, CIFAR-10 Batch 1:  Loss: 0.627499 Accuracy: 0.779639 Validation Loss: 1.10385 Validation Accuracy: 0.6244\n",
      "Epoch 159, CIFAR-10 Batch 2:  Loss: 0.600931 Accuracy: 0.802835 Validation Loss: 1.10797 Validation Accuracy: 0.6186\n",
      "Epoch 159, CIFAR-10 Batch 3:  Loss: 0.610646 Accuracy: 0.810567 Validation Loss: 1.10474 Validation Accuracy: 0.6178\n",
      "Epoch 159, CIFAR-10 Batch 4:  Loss: 0.622444 Accuracy: 0.796392 Validation Loss: 1.10175 Validation Accuracy: 0.6216\n",
      "Epoch 159, CIFAR-10 Batch 5:  Loss: 0.600744 Accuracy: 0.792526 Validation Loss: 1.10394 Validation Accuracy: 0.6208\n",
      "Epoch 160, CIFAR-10 Batch 1:  Loss: 0.615671 Accuracy: 0.783505 Validation Loss: 1.10132 Validation Accuracy: 0.6212\n",
      "Epoch 160, CIFAR-10 Batch 2:  Loss: 0.601228 Accuracy: 0.79768 Validation Loss: 1.10354 Validation Accuracy: 0.622\n",
      "Epoch 160, CIFAR-10 Batch 3:  Loss: 0.600288 Accuracy: 0.811856 Validation Loss: 1.10098 Validation Accuracy: 0.6162\n",
      "Epoch 160, CIFAR-10 Batch 4:  Loss: 0.612469 Accuracy: 0.792526 Validation Loss: 1.09449 Validation Accuracy: 0.6244\n",
      "Epoch 160, CIFAR-10 Batch 5:  Loss: 0.601197 Accuracy: 0.798969 Validation Loss: 1.10736 Validation Accuracy: 0.6188\n",
      "Epoch 161, CIFAR-10 Batch 1:  Loss: 0.625769 Accuracy: 0.787371 Validation Loss: 1.10616 Validation Accuracy: 0.6198\n",
      "Epoch 161, CIFAR-10 Batch 2:  Loss: 0.588233 Accuracy: 0.811856 Validation Loss: 1.10209 Validation Accuracy: 0.6228\n",
      "Epoch 161, CIFAR-10 Batch 3:  Loss: 0.605332 Accuracy: 0.806701 Validation Loss: 1.11124 Validation Accuracy: 0.6128\n",
      "Epoch 161, CIFAR-10 Batch 4:  Loss: 0.621076 Accuracy: 0.796392 Validation Loss: 1.10004 Validation Accuracy: 0.6226\n",
      "Epoch 161, CIFAR-10 Batch 5:  Loss: 0.597896 Accuracy: 0.804124 Validation Loss: 1.10043 Validation Accuracy: 0.6234\n",
      "Epoch 162, CIFAR-10 Batch 1:  Loss: 0.615496 Accuracy: 0.78866 Validation Loss: 1.10161 Validation Accuracy: 0.622\n",
      "Epoch 162, CIFAR-10 Batch 2:  Loss: 0.598269 Accuracy: 0.806701 Validation Loss: 1.10785 Validation Accuracy: 0.617\n",
      "Epoch 162, CIFAR-10 Batch 3:  Loss: 0.596626 Accuracy: 0.815722 Validation Loss: 1.10023 Validation Accuracy: 0.618\n",
      "Epoch 162, CIFAR-10 Batch 4:  Loss: 0.627816 Accuracy: 0.774484 Validation Loss: 1.1014 Validation Accuracy: 0.6234\n",
      "Epoch 162, CIFAR-10 Batch 5:  Loss: 0.592025 Accuracy: 0.804124 Validation Loss: 1.1018 Validation Accuracy: 0.6248\n",
      "Epoch 163, CIFAR-10 Batch 1:  Loss: 0.615648 Accuracy: 0.791237 Validation Loss: 1.1139 Validation Accuracy: 0.6208\n",
      "Epoch 163, CIFAR-10 Batch 2:  Loss: 0.597522 Accuracy: 0.798969 Validation Loss: 1.10391 Validation Accuracy: 0.6198\n",
      "Epoch 163, CIFAR-10 Batch 3:  Loss: 0.597961 Accuracy: 0.81701 Validation Loss: 1.10513 Validation Accuracy: 0.617\n",
      "Epoch 163, CIFAR-10 Batch 4:  Loss: 0.614698 Accuracy: 0.783505 Validation Loss: 1.09671 Validation Accuracy: 0.6252\n",
      "Epoch 163, CIFAR-10 Batch 5:  Loss: 0.587428 Accuracy: 0.804124 Validation Loss: 1.09469 Validation Accuracy: 0.6262\n",
      "Epoch 164, CIFAR-10 Batch 1:  Loss: 0.630879 Accuracy: 0.783505 Validation Loss: 1.1241 Validation Accuracy: 0.6184\n",
      "Epoch 164, CIFAR-10 Batch 2:  Loss: 0.608832 Accuracy: 0.805412 Validation Loss: 1.11973 Validation Accuracy: 0.612\n",
      "Epoch 164, CIFAR-10 Batch 3:  Loss: 0.595501 Accuracy: 0.818299 Validation Loss: 1.11007 Validation Accuracy: 0.6196\n",
      "Epoch 164, CIFAR-10 Batch 4:  Loss: 0.639491 Accuracy: 0.76933 Validation Loss: 1.11224 Validation Accuracy: 0.6186\n",
      "Epoch 164, CIFAR-10 Batch 5:  Loss: 0.592645 Accuracy: 0.801546 Validation Loss: 1.10738 Validation Accuracy: 0.6198\n",
      "Epoch 165, CIFAR-10 Batch 1:  Loss: 0.642431 Accuracy: 0.783505 Validation Loss: 1.13172 Validation Accuracy: 0.6156\n",
      "Epoch 165, CIFAR-10 Batch 2:  Loss: 0.624356 Accuracy: 0.798969 Validation Loss: 1.13383 Validation Accuracy: 0.6098\n",
      "Epoch 165, CIFAR-10 Batch 3:  Loss: 0.621197 Accuracy: 0.798969 Validation Loss: 1.12834 Validation Accuracy: 0.6064\n",
      "Epoch 165, CIFAR-10 Batch 4:  Loss: 0.63751 Accuracy: 0.77835 Validation Loss: 1.10416 Validation Accuracy: 0.6218\n",
      "Epoch 165, CIFAR-10 Batch 5:  Loss: 0.61348 Accuracy: 0.796392 Validation Loss: 1.12349 Validation Accuracy: 0.6154\n",
      "Epoch 166, CIFAR-10 Batch 1:  Loss: 0.646573 Accuracy: 0.775773 Validation Loss: 1.13237 Validation Accuracy: 0.612\n",
      "Epoch 166, CIFAR-10 Batch 2:  Loss: 0.611916 Accuracy: 0.802835 Validation Loss: 1.11714 Validation Accuracy: 0.6148\n",
      "Epoch 166, CIFAR-10 Batch 3:  Loss: 0.616174 Accuracy: 0.800258 Validation Loss: 1.11607 Validation Accuracy: 0.6124\n",
      "Epoch 166, CIFAR-10 Batch 4:  Loss: 0.626467 Accuracy: 0.786082 Validation Loss: 1.10717 Validation Accuracy: 0.6218\n",
      "Epoch 166, CIFAR-10 Batch 5:  Loss: 0.612113 Accuracy: 0.789948 Validation Loss: 1.11873 Validation Accuracy: 0.617\n",
      "Epoch 167, CIFAR-10 Batch 1:  Loss: 0.638819 Accuracy: 0.779639 Validation Loss: 1.12492 Validation Accuracy: 0.6194\n",
      "Epoch 167, CIFAR-10 Batch 2:  Loss: 0.604408 Accuracy: 0.809278 Validation Loss: 1.10749 Validation Accuracy: 0.6126\n",
      "Epoch 167, CIFAR-10 Batch 3:  Loss: 0.599273 Accuracy: 0.811856 Validation Loss: 1.10913 Validation Accuracy: 0.6138\n",
      "Epoch 167, CIFAR-10 Batch 4:  Loss: 0.619448 Accuracy: 0.784794 Validation Loss: 1.10292 Validation Accuracy: 0.621\n",
      "Epoch 167, CIFAR-10 Batch 5:  Loss: 0.601482 Accuracy: 0.802835 Validation Loss: 1.11792 Validation Accuracy: 0.6176\n",
      "Epoch 168, CIFAR-10 Batch 1:  Loss: 0.622808 Accuracy: 0.782216 Validation Loss: 1.10812 Validation Accuracy: 0.6228\n",
      "Epoch 168, CIFAR-10 Batch 2:  Loss: 0.585537 Accuracy: 0.813144 Validation Loss: 1.11841 Validation Accuracy: 0.6208\n",
      "Epoch 168, CIFAR-10 Batch 3:  Loss: 0.597787 Accuracy: 0.820876 Validation Loss: 1.10803 Validation Accuracy: 0.6148\n",
      "Epoch 168, CIFAR-10 Batch 4:  Loss: 0.611596 Accuracy: 0.800258 Validation Loss: 1.11311 Validation Accuracy: 0.6168\n",
      "Epoch 168, CIFAR-10 Batch 5:  Loss: 0.594611 Accuracy: 0.796392 Validation Loss: 1.10533 Validation Accuracy: 0.6204\n",
      "Epoch 169, CIFAR-10 Batch 1:  Loss: 0.619738 Accuracy: 0.786082 Validation Loss: 1.11682 Validation Accuracy: 0.6216\n",
      "Epoch 169, CIFAR-10 Batch 2:  Loss: 0.583475 Accuracy: 0.814433 Validation Loss: 1.09973 Validation Accuracy: 0.622\n",
      "Epoch 169, CIFAR-10 Batch 3:  Loss: 0.619859 Accuracy: 0.793814 Validation Loss: 1.14007 Validation Accuracy: 0.609\n",
      "Epoch 169, CIFAR-10 Batch 4:  Loss: 0.611739 Accuracy: 0.805412 Validation Loss: 1.10268 Validation Accuracy: 0.6196\n",
      "Epoch 169, CIFAR-10 Batch 5:  Loss: 0.602165 Accuracy: 0.793814 Validation Loss: 1.11158 Validation Accuracy: 0.6196\n",
      "Epoch 170, CIFAR-10 Batch 1:  Loss: 0.62 Accuracy: 0.787371 Validation Loss: 1.10827 Validation Accuracy: 0.6262\n",
      "Epoch 170, CIFAR-10 Batch 2:  Loss: 0.584377 Accuracy: 0.823454 Validation Loss: 1.12043 Validation Accuracy: 0.6146\n",
      "Epoch 170, CIFAR-10 Batch 3:  Loss: 0.60397 Accuracy: 0.815722 Validation Loss: 1.12272 Validation Accuracy: 0.6098\n",
      "Epoch 170, CIFAR-10 Batch 4:  Loss: 0.600967 Accuracy: 0.809278 Validation Loss: 1.11064 Validation Accuracy: 0.6154\n",
      "Epoch 170, CIFAR-10 Batch 5:  Loss: 0.606607 Accuracy: 0.796392 Validation Loss: 1.12527 Validation Accuracy: 0.6166\n",
      "Epoch 171, CIFAR-10 Batch 1:  Loss: 0.631028 Accuracy: 0.786082 Validation Loss: 1.12722 Validation Accuracy: 0.6154\n",
      "Epoch 171, CIFAR-10 Batch 2:  Loss: 0.593331 Accuracy: 0.809278 Validation Loss: 1.12994 Validation Accuracy: 0.6162\n",
      "Epoch 171, CIFAR-10 Batch 3:  Loss: 0.610474 Accuracy: 0.809278 Validation Loss: 1.12014 Validation Accuracy: 0.6128\n",
      "Epoch 171, CIFAR-10 Batch 4:  Loss: 0.6173 Accuracy: 0.809278 Validation Loss: 1.12586 Validation Accuracy: 0.6076\n",
      "Epoch 171, CIFAR-10 Batch 5:  Loss: 0.594066 Accuracy: 0.806701 Validation Loss: 1.1354 Validation Accuracy: 0.6148\n",
      "Epoch 172, CIFAR-10 Batch 1:  Loss: 0.647115 Accuracy: 0.786082 Validation Loss: 1.13655 Validation Accuracy: 0.6132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172, CIFAR-10 Batch 2:  Loss: 0.626036 Accuracy: 0.78866 Validation Loss: 1.15292 Validation Accuracy: 0.6048\n",
      "Epoch 172, CIFAR-10 Batch 3:  Loss: 0.647848 Accuracy: 0.798969 Validation Loss: 1.1554 Validation Accuracy: 0.6024\n",
      "Epoch 172, CIFAR-10 Batch 4:  Loss: 0.660684 Accuracy: 0.770618 Validation Loss: 1.17205 Validation Accuracy: 0.598\n",
      "Epoch 172, CIFAR-10 Batch 5:  Loss: 0.612445 Accuracy: 0.800258 Validation Loss: 1.14418 Validation Accuracy: 0.6092\n",
      "Epoch 173, CIFAR-10 Batch 1:  Loss: 0.650004 Accuracy: 0.779639 Validation Loss: 1.13592 Validation Accuracy: 0.6126\n",
      "Epoch 173, CIFAR-10 Batch 2:  Loss: 0.597104 Accuracy: 0.796392 Validation Loss: 1.12251 Validation Accuracy: 0.6152\n",
      "Epoch 173, CIFAR-10 Batch 3:  Loss: 0.614528 Accuracy: 0.822165 Validation Loss: 1.09386 Validation Accuracy: 0.6176\n",
      "Epoch 173, CIFAR-10 Batch 4:  Loss: 0.626525 Accuracy: 0.789948 Validation Loss: 1.12472 Validation Accuracy: 0.6156\n",
      "Epoch 173, CIFAR-10 Batch 5:  Loss: 0.605026 Accuracy: 0.801546 Validation Loss: 1.11762 Validation Accuracy: 0.6182\n",
      "Epoch 174, CIFAR-10 Batch 1:  Loss: 0.634831 Accuracy: 0.780928 Validation Loss: 1.12645 Validation Accuracy: 0.6178\n",
      "Epoch 174, CIFAR-10 Batch 2:  Loss: 0.574834 Accuracy: 0.824742 Validation Loss: 1.10222 Validation Accuracy: 0.6254\n",
      "Epoch 174, CIFAR-10 Batch 3:  Loss: 0.591675 Accuracy: 0.829897 Validation Loss: 1.10605 Validation Accuracy: 0.6178\n",
      "Epoch 174, CIFAR-10 Batch 4:  Loss: 0.598861 Accuracy: 0.806701 Validation Loss: 1.10644 Validation Accuracy: 0.6204\n",
      "Epoch 174, CIFAR-10 Batch 5:  Loss: 0.581185 Accuracy: 0.810567 Validation Loss: 1.12774 Validation Accuracy: 0.617\n",
      "Epoch 175, CIFAR-10 Batch 1:  Loss: 0.64015 Accuracy: 0.774484 Validation Loss: 1.13765 Validation Accuracy: 0.6128\n",
      "Epoch 175, CIFAR-10 Batch 2:  Loss: 0.568563 Accuracy: 0.820876 Validation Loss: 1.09388 Validation Accuracy: 0.625\n",
      "Epoch 175, CIFAR-10 Batch 3:  Loss: 0.589557 Accuracy: 0.820876 Validation Loss: 1.1059 Validation Accuracy: 0.6188\n",
      "Epoch 175, CIFAR-10 Batch 4:  Loss: 0.607618 Accuracy: 0.809278 Validation Loss: 1.11858 Validation Accuracy: 0.611\n",
      "Epoch 175, CIFAR-10 Batch 5:  Loss: 0.617438 Accuracy: 0.801546 Validation Loss: 1.15691 Validation Accuracy: 0.6062\n",
      "Epoch 176, CIFAR-10 Batch 1:  Loss: 0.638672 Accuracy: 0.786083 Validation Loss: 1.1407 Validation Accuracy: 0.6088\n",
      "Epoch 176, CIFAR-10 Batch 2:  Loss: 0.589748 Accuracy: 0.809278 Validation Loss: 1.13317 Validation Accuracy: 0.6132\n",
      "Epoch 176, CIFAR-10 Batch 3:  Loss: 0.612286 Accuracy: 0.823454 Validation Loss: 1.13739 Validation Accuracy: 0.6094\n",
      "Epoch 176, CIFAR-10 Batch 4:  Loss: 0.615126 Accuracy: 0.804124 Validation Loss: 1.12453 Validation Accuracy: 0.6142\n",
      "Epoch 176, CIFAR-10 Batch 5:  Loss: 0.610737 Accuracy: 0.792526 Validation Loss: 1.16279 Validation Accuracy: 0.6046\n",
      "Epoch 177, CIFAR-10 Batch 1:  Loss: 0.66162 Accuracy: 0.770618 Validation Loss: 1.1679 Validation Accuracy: 0.5998\n",
      "Epoch 177, CIFAR-10 Batch 2:  Loss: 0.616601 Accuracy: 0.793814 Validation Loss: 1.16228 Validation Accuracy: 0.5998\n",
      "Epoch 177, CIFAR-10 Batch 3:  Loss: 0.61806 Accuracy: 0.820876 Validation Loss: 1.14543 Validation Accuracy: 0.606\n",
      "Epoch 177, CIFAR-10 Batch 4:  Loss: 0.628265 Accuracy: 0.793814 Validation Loss: 1.15216 Validation Accuracy: 0.6084\n",
      "Epoch 177, CIFAR-10 Batch 5:  Loss: 0.589677 Accuracy: 0.814433 Validation Loss: 1.12294 Validation Accuracy: 0.6116\n",
      "Epoch 178, CIFAR-10 Batch 1:  Loss: 0.609413 Accuracy: 0.793814 Validation Loss: 1.11042 Validation Accuracy: 0.6196\n",
      "Epoch 178, CIFAR-10 Batch 2:  Loss: 0.583118 Accuracy: 0.814433 Validation Loss: 1.13396 Validation Accuracy: 0.6144\n",
      "Epoch 178, CIFAR-10 Batch 3:  Loss: 0.587527 Accuracy: 0.820876 Validation Loss: 1.11191 Validation Accuracy: 0.6146\n",
      "Epoch 178, CIFAR-10 Batch 4:  Loss: 0.601629 Accuracy: 0.810567 Validation Loss: 1.10392 Validation Accuracy: 0.6198\n",
      "Epoch 178, CIFAR-10 Batch 5:  Loss: 0.58961 Accuracy: 0.80799 Validation Loss: 1.11695 Validation Accuracy: 0.616\n",
      "Epoch 179, CIFAR-10 Batch 1:  Loss: 0.618967 Accuracy: 0.792526 Validation Loss: 1.13134 Validation Accuracy: 0.6192\n",
      "Epoch 179, CIFAR-10 Batch 2:  Loss: 0.567018 Accuracy: 0.818299 Validation Loss: 1.10946 Validation Accuracy: 0.6232\n",
      "Epoch 179, CIFAR-10 Batch 3:  Loss: 0.576633 Accuracy: 0.838917 Validation Loss: 1.10908 Validation Accuracy: 0.6146\n",
      "Epoch 179, CIFAR-10 Batch 4:  Loss: 0.58893 Accuracy: 0.813144 Validation Loss: 1.11532 Validation Accuracy: 0.6166\n",
      "Epoch 179, CIFAR-10 Batch 5:  Loss: 0.584853 Accuracy: 0.805412 Validation Loss: 1.12818 Validation Accuracy: 0.6164\n",
      "Epoch 180, CIFAR-10 Batch 1:  Loss: 0.631883 Accuracy: 0.783505 Validation Loss: 1.1468 Validation Accuracy: 0.614\n",
      "Epoch 180, CIFAR-10 Batch 2:  Loss: 0.571582 Accuracy: 0.810567 Validation Loss: 1.11176 Validation Accuracy: 0.6214\n",
      "Epoch 180, CIFAR-10 Batch 3:  Loss: 0.598446 Accuracy: 0.823454 Validation Loss: 1.12883 Validation Accuracy: 0.609\n",
      "Epoch 180, CIFAR-10 Batch 4:  Loss: 0.597578 Accuracy: 0.80799 Validation Loss: 1.11714 Validation Accuracy: 0.6166\n",
      "Epoch 180, CIFAR-10 Batch 5:  Loss: 0.612669 Accuracy: 0.787371 Validation Loss: 1.16095 Validation Accuracy: 0.6012\n",
      "Epoch 181, CIFAR-10 Batch 1:  Loss: 0.634129 Accuracy: 0.783505 Validation Loss: 1.14941 Validation Accuracy: 0.6112\n",
      "Epoch 181, CIFAR-10 Batch 2:  Loss: 0.581638 Accuracy: 0.805412 Validation Loss: 1.13557 Validation Accuracy: 0.6096\n",
      "Epoch 181, CIFAR-10 Batch 3:  Loss: 0.600006 Accuracy: 0.815722 Validation Loss: 1.13963 Validation Accuracy: 0.6076\n",
      "Epoch 181, CIFAR-10 Batch 4:  Loss: 0.591871 Accuracy: 0.813144 Validation Loss: 1.11 Validation Accuracy: 0.6148\n",
      "Epoch 181, CIFAR-10 Batch 5:  Loss: 0.606048 Accuracy: 0.784794 Validation Loss: 1.15729 Validation Accuracy: 0.6114\n",
      "Epoch 182, CIFAR-10 Batch 1:  Loss: 0.601101 Accuracy: 0.800258 Validation Loss: 1.10886 Validation Accuracy: 0.6194\n",
      "Epoch 182, CIFAR-10 Batch 2:  Loss: 0.58257 Accuracy: 0.820876 Validation Loss: 1.14908 Validation Accuracy: 0.6116\n",
      "Epoch 182, CIFAR-10 Batch 3:  Loss: 0.584128 Accuracy: 0.824742 Validation Loss: 1.10353 Validation Accuracy: 0.6202\n",
      "Epoch 182, CIFAR-10 Batch 4:  Loss: 0.600236 Accuracy: 0.791237 Validation Loss: 1.11022 Validation Accuracy: 0.617\n",
      "Epoch 182, CIFAR-10 Batch 5:  Loss: 0.577762 Accuracy: 0.813144 Validation Loss: 1.11013 Validation Accuracy: 0.6212\n",
      "Epoch 183, CIFAR-10 Batch 1:  Loss: 0.631122 Accuracy: 0.787371 Validation Loss: 1.14341 Validation Accuracy: 0.6132\n",
      "Epoch 183, CIFAR-10 Batch 2:  Loss: 0.554973 Accuracy: 0.832474 Validation Loss: 1.10201 Validation Accuracy: 0.6212\n",
      "Epoch 183, CIFAR-10 Batch 3:  Loss: 0.599253 Accuracy: 0.802835 Validation Loss: 1.09829 Validation Accuracy: 0.6196\n",
      "Epoch 183, CIFAR-10 Batch 4:  Loss: 0.567612 Accuracy: 0.80799 Validation Loss: 1.09893 Validation Accuracy: 0.623\n",
      "Epoch 183, CIFAR-10 Batch 5:  Loss: 0.564844 Accuracy: 0.828608 Validation Loss: 1.10928 Validation Accuracy: 0.6198\n",
      "Epoch 184, CIFAR-10 Batch 1:  Loss: 0.605498 Accuracy: 0.798969 Validation Loss: 1.13019 Validation Accuracy: 0.6148\n",
      "Epoch 184, CIFAR-10 Batch 2:  Loss: 0.557224 Accuracy: 0.820876 Validation Loss: 1.11313 Validation Accuracy: 0.6216\n",
      "Epoch 184, CIFAR-10 Batch 3:  Loss: 0.569626 Accuracy: 0.82732 Validation Loss: 1.0905 Validation Accuracy: 0.6284\n",
      "Epoch 184, CIFAR-10 Batch 4:  Loss: 0.55911 Accuracy: 0.818299 Validation Loss: 1.09147 Validation Accuracy: 0.624\n",
      "Epoch 184, CIFAR-10 Batch 5:  Loss: 0.559285 Accuracy: 0.826031 Validation Loss: 1.11381 Validation Accuracy: 0.6214\n",
      "Epoch 185, CIFAR-10 Batch 1:  Loss: 0.608266 Accuracy: 0.791237 Validation Loss: 1.13824 Validation Accuracy: 0.6148\n",
      "Epoch 185, CIFAR-10 Batch 2:  Loss: 0.549509 Accuracy: 0.832474 Validation Loss: 1.10837 Validation Accuracy: 0.6234\n",
      "Epoch 185, CIFAR-10 Batch 3:  Loss: 0.557279 Accuracy: 0.835051 Validation Loss: 1.0941 Validation Accuracy: 0.6244\n",
      "Epoch 185, CIFAR-10 Batch 4:  Loss: 0.568067 Accuracy: 0.811856 Validation Loss: 1.10035 Validation Accuracy: 0.622\n",
      "Epoch 185, CIFAR-10 Batch 5:  Loss: 0.571772 Accuracy: 0.822165 Validation Loss: 1.13422 Validation Accuracy: 0.6162\n",
      "Epoch 186, CIFAR-10 Batch 1:  Loss: 0.602122 Accuracy: 0.798969 Validation Loss: 1.13294 Validation Accuracy: 0.6176\n",
      "Epoch 186, CIFAR-10 Batch 2:  Loss: 0.545232 Accuracy: 0.828608 Validation Loss: 1.11337 Validation Accuracy: 0.623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186, CIFAR-10 Batch 3:  Loss: 0.56281 Accuracy: 0.82732 Validation Loss: 1.09922 Validation Accuracy: 0.623\n",
      "Epoch 186, CIFAR-10 Batch 4:  Loss: 0.575722 Accuracy: 0.813144 Validation Loss: 1.12325 Validation Accuracy: 0.6182\n",
      "Epoch 186, CIFAR-10 Batch 5:  Loss: 0.559141 Accuracy: 0.81701 Validation Loss: 1.11812 Validation Accuracy: 0.6182\n",
      "Epoch 187, CIFAR-10 Batch 1:  Loss: 0.606082 Accuracy: 0.787371 Validation Loss: 1.13837 Validation Accuracy: 0.6178\n",
      "Epoch 187, CIFAR-10 Batch 2:  Loss: 0.545761 Accuracy: 0.832474 Validation Loss: 1.10824 Validation Accuracy: 0.6184\n",
      "Epoch 187, CIFAR-10 Batch 3:  Loss: 0.559883 Accuracy: 0.833763 Validation Loss: 1.10814 Validation Accuracy: 0.6218\n",
      "Epoch 187, CIFAR-10 Batch 4:  Loss: 0.5599 Accuracy: 0.809278 Validation Loss: 1.10533 Validation Accuracy: 0.6208\n",
      "Epoch 187, CIFAR-10 Batch 5:  Loss: 0.550587 Accuracy: 0.823453 Validation Loss: 1.11886 Validation Accuracy: 0.6188\n",
      "Epoch 188, CIFAR-10 Batch 1:  Loss: 0.60556 Accuracy: 0.791237 Validation Loss: 1.14179 Validation Accuracy: 0.6134\n",
      "Epoch 188, CIFAR-10 Batch 2:  Loss: 0.549119 Accuracy: 0.831185 Validation Loss: 1.10955 Validation Accuracy: 0.6216\n",
      "Epoch 188, CIFAR-10 Batch 3:  Loss: 0.558933 Accuracy: 0.832474 Validation Loss: 1.09917 Validation Accuracy: 0.6256\n",
      "Epoch 188, CIFAR-10 Batch 4:  Loss: 0.577403 Accuracy: 0.81701 Validation Loss: 1.12664 Validation Accuracy: 0.6158\n",
      "Epoch 188, CIFAR-10 Batch 5:  Loss: 0.563005 Accuracy: 0.826031 Validation Loss: 1.10933 Validation Accuracy: 0.6212\n",
      "Epoch 189, CIFAR-10 Batch 1:  Loss: 0.609083 Accuracy: 0.789948 Validation Loss: 1.14677 Validation Accuracy: 0.612\n",
      "Epoch 189, CIFAR-10 Batch 2:  Loss: 0.545456 Accuracy: 0.837629 Validation Loss: 1.11504 Validation Accuracy: 0.62\n",
      "Epoch 189, CIFAR-10 Batch 3:  Loss: 0.575384 Accuracy: 0.820876 Validation Loss: 1.11372 Validation Accuracy: 0.6216\n",
      "Epoch 189, CIFAR-10 Batch 4:  Loss: 0.577825 Accuracy: 0.810567 Validation Loss: 1.13896 Validation Accuracy: 0.6152\n",
      "Epoch 189, CIFAR-10 Batch 5:  Loss: 0.556079 Accuracy: 0.823454 Validation Loss: 1.11825 Validation Accuracy: 0.6192\n",
      "Epoch 190, CIFAR-10 Batch 1:  Loss: 0.608137 Accuracy: 0.796392 Validation Loss: 1.1466 Validation Accuracy: 0.6132\n",
      "Epoch 190, CIFAR-10 Batch 2:  Loss: 0.543086 Accuracy: 0.835051 Validation Loss: 1.11029 Validation Accuracy: 0.6222\n",
      "Epoch 190, CIFAR-10 Batch 3:  Loss: 0.573112 Accuracy: 0.828608 Validation Loss: 1.11016 Validation Accuracy: 0.621\n",
      "Epoch 190, CIFAR-10 Batch 4:  Loss: 0.566948 Accuracy: 0.818299 Validation Loss: 1.12076 Validation Accuracy: 0.618\n",
      "Epoch 190, CIFAR-10 Batch 5:  Loss: 0.56231 Accuracy: 0.823454 Validation Loss: 1.12378 Validation Accuracy: 0.6182\n",
      "Epoch 191, CIFAR-10 Batch 1:  Loss: 0.608855 Accuracy: 0.793814 Validation Loss: 1.15434 Validation Accuracy: 0.6144\n",
      "Epoch 191, CIFAR-10 Batch 2:  Loss: 0.542029 Accuracy: 0.833763 Validation Loss: 1.124 Validation Accuracy: 0.6216\n",
      "Epoch 191, CIFAR-10 Batch 3:  Loss: 0.582666 Accuracy: 0.822165 Validation Loss: 1.11769 Validation Accuracy: 0.6178\n",
      "Epoch 191, CIFAR-10 Batch 4:  Loss: 0.569151 Accuracy: 0.81701 Validation Loss: 1.12362 Validation Accuracy: 0.619\n",
      "Epoch 191, CIFAR-10 Batch 5:  Loss: 0.558313 Accuracy: 0.824742 Validation Loss: 1.11704 Validation Accuracy: 0.6176\n",
      "Epoch 192, CIFAR-10 Batch 1:  Loss: 0.620627 Accuracy: 0.787371 Validation Loss: 1.16193 Validation Accuracy: 0.613\n",
      "Epoch 192, CIFAR-10 Batch 2:  Loss: 0.552407 Accuracy: 0.829897 Validation Loss: 1.12354 Validation Accuracy: 0.619\n",
      "Epoch 192, CIFAR-10 Batch 3:  Loss: 0.567582 Accuracy: 0.833763 Validation Loss: 1.11334 Validation Accuracy: 0.619\n",
      "Epoch 192, CIFAR-10 Batch 4:  Loss: 0.562606 Accuracy: 0.822165 Validation Loss: 1.12313 Validation Accuracy: 0.6166\n",
      "Epoch 192, CIFAR-10 Batch 5:  Loss: 0.560087 Accuracy: 0.828608 Validation Loss: 1.12645 Validation Accuracy: 0.6162\n",
      "Epoch 193, CIFAR-10 Batch 1:  Loss: 0.598319 Accuracy: 0.796392 Validation Loss: 1.14188 Validation Accuracy: 0.6146\n",
      "Epoch 193, CIFAR-10 Batch 2:  Loss: 0.547058 Accuracy: 0.822165 Validation Loss: 1.12046 Validation Accuracy: 0.6176\n",
      "Epoch 193, CIFAR-10 Batch 3:  Loss: 0.565229 Accuracy: 0.83634 Validation Loss: 1.10944 Validation Accuracy: 0.6214\n",
      "Epoch 193, CIFAR-10 Batch 4:  Loss: 0.565904 Accuracy: 0.823454 Validation Loss: 1.12338 Validation Accuracy: 0.618\n",
      "Epoch 193, CIFAR-10 Batch 5:  Loss: 0.563383 Accuracy: 0.823454 Validation Loss: 1.11944 Validation Accuracy: 0.6186\n",
      "Epoch 194, CIFAR-10 Batch 1:  Loss: 0.605328 Accuracy: 0.795103 Validation Loss: 1.15059 Validation Accuracy: 0.6154\n",
      "Epoch 194, CIFAR-10 Batch 2:  Loss: 0.54441 Accuracy: 0.833763 Validation Loss: 1.12163 Validation Accuracy: 0.6216\n",
      "Epoch 194, CIFAR-10 Batch 3:  Loss: 0.565514 Accuracy: 0.833763 Validation Loss: 1.11088 Validation Accuracy: 0.622\n",
      "Epoch 194, CIFAR-10 Batch 4:  Loss: 0.553911 Accuracy: 0.823454 Validation Loss: 1.12643 Validation Accuracy: 0.6194\n",
      "Epoch 194, CIFAR-10 Batch 5:  Loss: 0.558946 Accuracy: 0.829897 Validation Loss: 1.12171 Validation Accuracy: 0.6178\n",
      "Epoch 195, CIFAR-10 Batch 1:  Loss: 0.597763 Accuracy: 0.800258 Validation Loss: 1.14487 Validation Accuracy: 0.618\n",
      "Epoch 195, CIFAR-10 Batch 2:  Loss: 0.52454 Accuracy: 0.833763 Validation Loss: 1.11295 Validation Accuracy: 0.6232\n",
      "Epoch 195, CIFAR-10 Batch 3:  Loss: 0.567918 Accuracy: 0.824742 Validation Loss: 1.11997 Validation Accuracy: 0.6214\n",
      "Epoch 195, CIFAR-10 Batch 4:  Loss: 0.556095 Accuracy: 0.814433 Validation Loss: 1.12593 Validation Accuracy: 0.619\n",
      "Epoch 195, CIFAR-10 Batch 5:  Loss: 0.561582 Accuracy: 0.823454 Validation Loss: 1.12152 Validation Accuracy: 0.6182\n",
      "Epoch 196, CIFAR-10 Batch 1:  Loss: 0.581858 Accuracy: 0.802835 Validation Loss: 1.13579 Validation Accuracy: 0.622\n",
      "Epoch 196, CIFAR-10 Batch 2:  Loss: 0.528846 Accuracy: 0.83634 Validation Loss: 1.10924 Validation Accuracy: 0.6194\n",
      "Epoch 196, CIFAR-10 Batch 3:  Loss: 0.575213 Accuracy: 0.833763 Validation Loss: 1.11755 Validation Accuracy: 0.6194\n",
      "Epoch 196, CIFAR-10 Batch 4:  Loss: 0.567445 Accuracy: 0.819588 Validation Loss: 1.13019 Validation Accuracy: 0.6136\n",
      "Epoch 196, CIFAR-10 Batch 5:  Loss: 0.571072 Accuracy: 0.819588 Validation Loss: 1.13281 Validation Accuracy: 0.6174\n",
      "Epoch 197, CIFAR-10 Batch 1:  Loss: 0.57936 Accuracy: 0.806701 Validation Loss: 1.13587 Validation Accuracy: 0.6206\n",
      "Epoch 197, CIFAR-10 Batch 2:  Loss: 0.538159 Accuracy: 0.824742 Validation Loss: 1.14004 Validation Accuracy: 0.6154\n",
      "Epoch 197, CIFAR-10 Batch 3:  Loss: 0.557839 Accuracy: 0.842783 Validation Loss: 1.10473 Validation Accuracy: 0.625\n",
      "Epoch 197, CIFAR-10 Batch 4:  Loss: 0.580001 Accuracy: 0.810567 Validation Loss: 1.14171 Validation Accuracy: 0.6086\n",
      "Epoch 197, CIFAR-10 Batch 5:  Loss: 0.561246 Accuracy: 0.829897 Validation Loss: 1.11924 Validation Accuracy: 0.6186\n",
      "Epoch 198, CIFAR-10 Batch 1:  Loss: 0.579308 Accuracy: 0.806701 Validation Loss: 1.14606 Validation Accuracy: 0.6176\n",
      "Epoch 198, CIFAR-10 Batch 2:  Loss: 0.536961 Accuracy: 0.826031 Validation Loss: 1.14677 Validation Accuracy: 0.6146\n",
      "Epoch 198, CIFAR-10 Batch 3:  Loss: 0.570071 Accuracy: 0.835051 Validation Loss: 1.11084 Validation Accuracy: 0.6214\n",
      "Epoch 198, CIFAR-10 Batch 4:  Loss: 0.5638 Accuracy: 0.823454 Validation Loss: 1.13294 Validation Accuracy: 0.61\n",
      "Epoch 198, CIFAR-10 Batch 5:  Loss: 0.547581 Accuracy: 0.826031 Validation Loss: 1.1282 Validation Accuracy: 0.6186\n",
      "Epoch 199, CIFAR-10 Batch 1:  Loss: 0.571709 Accuracy: 0.814433 Validation Loss: 1.13693 Validation Accuracy: 0.6234\n",
      "Epoch 199, CIFAR-10 Batch 2:  Loss: 0.522142 Accuracy: 0.833763 Validation Loss: 1.13023 Validation Accuracy: 0.6224\n",
      "Epoch 199, CIFAR-10 Batch 3:  Loss: 0.560634 Accuracy: 0.841495 Validation Loss: 1.10929 Validation Accuracy: 0.6222\n",
      "Epoch 199, CIFAR-10 Batch 4:  Loss: 0.542456 Accuracy: 0.822165 Validation Loss: 1.11183 Validation Accuracy: 0.6216\n",
      "Epoch 199, CIFAR-10 Batch 5:  Loss: 0.54718 Accuracy: 0.833763 Validation Loss: 1.1299 Validation Accuracy: 0.6204\n",
      "Epoch 200, CIFAR-10 Batch 1:  Loss: 0.568143 Accuracy: 0.810567 Validation Loss: 1.1408 Validation Accuracy: 0.6192\n",
      "Epoch 200, CIFAR-10 Batch 2:  Loss: 0.51386 Accuracy: 0.840206 Validation Loss: 1.12785 Validation Accuracy: 0.624\n",
      "Epoch 200, CIFAR-10 Batch 3:  Loss: 0.567502 Accuracy: 0.829897 Validation Loss: 1.11985 Validation Accuracy: 0.6196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200, CIFAR-10 Batch 4:  Loss: 0.545517 Accuracy: 0.820876 Validation Loss: 1.11182 Validation Accuracy: 0.62\n",
      "Epoch 200, CIFAR-10 Batch 5:  Loss: 0.534359 Accuracy: 0.824742 Validation Loss: 1.1243 Validation Accuracy: 0.6256\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.6150015473365784\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ccc36b7f0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-70% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 70%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
